{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% s0\n",
    "rid = 's0' # running id\n",
    "from math import ceil\n",
    "from utils import *\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "torch.set_printoptions(linewidth=160)\n",
    "from datetime import datetime\n",
    "print('starting date time ', datetime.now())\n",
    "torch.manual_seed(1)\n",
    "\n",
    "if torch.__version__[:5] != '1.8.1':\n",
    "    def mydet(x):\n",
    "        return x.det()\n",
    "    RAdam = torch.optim.RAdam\n",
    "else:\n",
    "    RAdam = optim.RAdam\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "from vae_model import *\n",
    "class NN_gtsbd(nn.Module):\n",
    "    \"\"\"This is recursive Wiener filter version, with Rb threshold of [1e-3, 1e2]\n",
    "    Input shape [I,M,N,F], e.g.[32,3,100,100]\n",
    "    J <=K\n",
    "    \"\"\"\n",
    "    def __init__(self, M=3, K=3, im_size=100):\n",
    "        super().__init__()\n",
    "        self.dz = 32\n",
    "        self.K, self.M = K, M\n",
    "\n",
    "        # Estimate H and coarse V\n",
    "        # self.est = nn.Sequential(\n",
    "        #     Down(in_channels=M*2, out_channels=64),\n",
    "        #     Down(in_channels=64, out_channels=32),\n",
    "        #     Down(in_channels=32, out_channels=4),\n",
    "        #     Reshape(-1, 4*12*12),\n",
    "        #     LinearBlock(4*12*12, 64),\n",
    "        #     nn.Linear(64, 1),\n",
    "        #     )\n",
    "        # self.b1 = nn.Linear(100, 1)\n",
    "        # self.b2 = nn.Linear(100, 1)\n",
    "           \n",
    "        # Estimate V using auto encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            Down(in_channels=1, out_channels=64),\n",
    "            Down(in_channels=64, out_channels=16),\n",
    "            OutConv(in_channels=16, out_channels=1),\n",
    "            )\n",
    "        self.fc1 = nn.Linear(25*25, 2*self.dz)\n",
    "        self.decoder = nn.Sequential(\n",
    "            DoubleConv(in_channels=self.dz+2, out_channels=64),\n",
    "            DoubleConv(in_channels=64, out_channels=16),\n",
    "            OutConv(in_channels=16, out_channels=1),\n",
    "            ) \n",
    "        self.im_size = im_size\n",
    "        x = torch.linspace(-1, 1, im_size)\n",
    "        y = torch.linspace(-1, 1, im_size)\n",
    "        x_grid, y_grid = torch.meshgrid(x, y)\n",
    "        # Add as constant, with extra dims for N and C\n",
    "        self.register_buffer('x_grid', x_grid.view((1, 1) + x_grid.shape))\n",
    "        self.register_buffer('y_grid', y_grid.view((1, 1) + y_grid.shape))\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, _, N, F = x.shape\n",
    "        z_all, v_all, h_all = [], [], []\n",
    "        I = x.shape[0]\n",
    "        \"Neural nets for H,V\"\n",
    "        shat_all = []\n",
    "        for i in range(self.K):\n",
    "            if i == 0:\n",
    "                inp = x\n",
    "            else:\n",
    "                tmp = hj[...,None]@W@inp.permute(2,3,0,1)[...,None]\n",
    "                inp = inp - tmp.squeeze().permute(2,3,0,1)\n",
    "\n",
    "            # sb = self.b2(self.b1(inp.abs()).squeeze()).mean(dim=1).exp()\n",
    "            # Rb = (sb[:None]*torch.ones(batch_size, self.M, \\\n",
    "            #     device=x.device)).diag_embed().to(torch.cfloat) # shape:[I, M, M]\n",
    "            Rb = (1.4e-3*torch.ones(batch_size, self.M, \\\n",
    "                device=x.device)).diag_embed().to(torch.cfloat) # shape:[I, M, M]\n",
    "            hj = hgt[:,i].repeat(I).reshape(I,3) # shape:[I, M]\n",
    "            h_all.append(hj)\n",
    "\n",
    "            \"Wienter filter to get coarse shat\"\n",
    "            Rx = hj[...,None] @ hj[:,None].conj() + Rb # shape of [I,M,M]\n",
    "            W = hj[:, None,].conj() @ Rx.inverse()  # shape of [N,F,I,1,M]\n",
    "            shat = (W @ inp.permute(2,3,0,1)[...,None]).squeeze().permute(2,0,1) #[I, N, F]\n",
    "            shat = shat/shat.detach().abs().max()\n",
    "            shat_all.append(shat)\n",
    "        \n",
    "        for i in range(self.K):\n",
    "            \"Encoder\"\n",
    "            xx = self.encoder(shat_all[i][:,None].abs())\n",
    "            \"Get latent variable\"\n",
    "            zz = self.fc1(xx.reshape(batch_size,-1))\n",
    "            mu = zz[:,::2]\n",
    "            logvar = zz[:,1::2]\n",
    "            z = self.reparameterize(mu, logvar)\n",
    "            z_all.append(z)\n",
    "            \n",
    "            \"Decoder to get V\"\n",
    "            # View z as 4D tensor to be tiled across new N and F dimensions            \n",
    "            zr = z.view((batch_size, self.dz)+ (1, 1))  #Shape: IxDxNxF\n",
    "            # Tile across to match image size\n",
    "            zr = zr.expand(-1, -1, self.im_size, self.im_size)  #Shape: IxDx64x64\n",
    "            # Expand grids to batches and concatenate on the channel dimension\n",
    "            zbd = torch.cat((self.x_grid.expand(batch_size, -1, -1, -1),\n",
    "                        self.y_grid.expand(batch_size, -1, -1, -1), zr), dim=1) # Shape: Ix(dz*K+2)xNxF\n",
    "            v = self.decoder(zbd).exp()\n",
    "            v_all.append(threshold(v, floor=1e-3, ceiling=1e2)) # 1e-3 to 1e2\n",
    "        Hhat = torch.stack(h_all, 2) # shape:[I, M, K]\n",
    "        vhat = torch.stack(v_all, 4).squeeze().to(torch.cfloat) # shape:[I, N, F, K]\n",
    "\n",
    "        return vhat.diag_embed(), Hhat, Rb, mu, logvar\n",
    "\n",
    "def loss_fun(x, Rs, Hhat, Rb, mu, logvar, beta=1e-3):\n",
    "    x = x.permute(0,2,3,1)\n",
    "    kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    Rxperm = Hhat @ Rs.permute(1,2,0,3,4) @ Hhat.transpose(-1,-2).conj() + Rb\n",
    "    Rx = Rxperm.permute(2,0,1,3,4) # shape of [I, N, F, M, M]\n",
    "    try:\n",
    "        ll = -(np.pi*mydet(Rx)).log() - (x[...,None,:].conj()@Rx.inverse()@x[...,None]).squeeze() \n",
    "    except:\n",
    "        torch.save((x, Rx, Rs, Hhat, Rb), f'rid{rid}x_Rx_Rs_Hhat_Rb.pt')\n",
    "        print('error happpened, data saved and stop')\n",
    "        ll = -(np.pi*mydet(Rx)).log() - (x[...,None,:].conj()@Rx.inverse()@x[...,None]).squeeze()\n",
    "    return -ll.sum().real, beta*kl\n",
    "\n",
    "#%%\n",
    "\n",
    "fig_loc = '../data/nem_ss/figures/'\n",
    "mod_loc = '../data/nem_ss/models/'\n",
    "if not(os.path.isdir(fig_loc + f'/{rid}/')): \n",
    "    print('made a new folder')\n",
    "    os.mkdir(fig_loc + f'{rid}/')\n",
    "    os.mkdir(mod_loc + f'{rid}/')\n",
    "fig_loc = fig_loc + f'{rid}/'\n",
    "mod_loc = mod_loc + f'{rid}/'\n",
    "\n",
    "I = 3000 # how many samples\n",
    "M, N, F, K = 3, 100, 100, 3\n",
    "NF = N*F\n",
    "eps = 5e-4\n",
    "opts = {}\n",
    "opts['batch_size'] = 64\n",
    "opts['lr'] = 1e-3\n",
    "opts['n_epochs'] = 150\n",
    "\n",
    "d = torch.load('../data/nem_ss/tr3kM3FT100.pt')\n",
    "d = awgn_batch(d, snr=30, seed=1)\n",
    "xtr = (d/d.abs().amax(dim=(1,2,3))[:,None,None,None]) # [sample,M,N,F]\n",
    "xtr = xtr.to(torch.cfloat)\n",
    "data = Data.TensorDataset(xtr[:I])\n",
    "tr = Data.DataLoader(data, batch_size=opts['batch_size'], shuffle=True, drop_last=True)\n",
    "xval, _ , hgt0 = torch.load('../data/nem_ss/val500M3FT100_xsh.pt')\n",
    "hgt = torch.tensor(hgt0).to(torch.cfloat).cuda()\n",
    "xval_cuda = xval[:128].to(torch.cfloat).cuda()\n",
    "\n",
    "loss_iter, loss_tr, loss1, loss2, loss_eval = [], [], [], [], []\n",
    "NN = NN_gtsbd\n",
    "model = NN(M,K,N).cuda()\n",
    "# for w in model.parameters():\n",
    "#     nn.init.normal_(w, mean=0., std=0.01)\n",
    "\n",
    "optimizer = RAdam(model.parameters(),\n",
    "                lr= opts['lr'],\n",
    "                betas=(0.9, 0.999), \n",
    "                eps=1e-8,\n",
    "                weight_decay=0)\n",
    "\n",
    "for epoch in range(opts['n_epochs']):\n",
    "    model.train()\n",
    "    for i, (x,) in enumerate(tr): \n",
    "        x = x.cuda()\n",
    "        optimizer.zero_grad()         \n",
    "        Rs, Hhat, Rb, mu, logvar= model(x)\n",
    "        l1, l2 = loss_fun(x, Rs, Hhat, Rb, mu, logvar)\n",
    "        loss = l1 + l2\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "        optimizer.step()\n",
    "        torch.cuda.empty_cache()\n",
    " \n",
    "    loss_tr.append(loss.detach().cpu().item()/opts['batch_size'])\n",
    "    loss1.append(l1.detach().cpu().item()/opts['batch_size'])\n",
    "    loss2.append(l2.detach().cpu().item()/opts['batch_size'])\n",
    "    if epoch%10 == 0:\n",
    "        plt.figure()\n",
    "        plt.plot(loss_tr, '-or')\n",
    "        plt.title(f'Loss fuction at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_LossFunAll')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss1, '-og')\n",
    "        plt.title(f'Reconstruction loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_Loss1')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss2, '-og')\n",
    "        plt.title(f'KL loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_Loss2')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss_tr[-50:], '-or')\n",
    "        plt.title(f'Last 50 of loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_last50')\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            Rs, Hhat, Rb, mu, logvar= model(xval_cuda)\n",
    "            l1, l2 = loss_fun(xval_cuda, Rs, Hhat, Rb, mu, logvar)\n",
    "            loss_eval.append((l1+l2).cpu().item()/128)\n",
    "            plt.figure()\n",
    "            plt.plot(loss_eval, '-xb')\n",
    "            plt.title(f'Accumulated validation loss at epoch{epoch}')\n",
    "            plt.savefig(fig_loc + f'Epoch{epoch}_val') \n",
    "            plt.close('all')           \n",
    "        torch.save(model, mod_loc+f'model_epoch{epoch}.pt')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% s1\n",
    "rid = 's1' # running id\n",
    "from math import ceil\n",
    "from utils import *\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "torch.set_printoptions(linewidth=160)\n",
    "from datetime import datetime\n",
    "print('starting date time ', datetime.now())\n",
    "torch.manual_seed(1)\n",
    "\n",
    "if torch.__version__[:5] != '1.8.1':\n",
    "    def mydet(x):\n",
    "        return x.det()\n",
    "    RAdam = torch.optim.RAdam\n",
    "else:\n",
    "    RAdam = optim.RAdam\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "from vae_model import *\n",
    "class NN_gtsbd(nn.Module):\n",
    "    \"\"\"This is recursive Wiener filter version, with Rb threshold of [1e-3, 1e2]\n",
    "    Input shape [I,M,N,F], e.g.[32,3,100,100]\n",
    "    J <=K\n",
    "    \"\"\"\n",
    "    def __init__(self, M=3, K=3, im_size=100):\n",
    "        super().__init__()\n",
    "        self.dz = 32\n",
    "        self.K, self.M = K, M\n",
    "\n",
    "        # Estimate H and coarse V\n",
    "        # self.est = nn.Sequential(\n",
    "        #     Down(in_channels=M*2, out_channels=64),\n",
    "        #     Down(in_channels=64, out_channels=32),\n",
    "        #     Down(in_channels=32, out_channels=4),\n",
    "        #     Reshape(-1, 4*12*12),\n",
    "        #     LinearBlock(4*12*12, 64),\n",
    "        #     nn.Linear(64, 1),\n",
    "        #     )\n",
    "        # self.b1 = nn.Linear(100, 1)\n",
    "        # self.b2 = nn.Linear(100, 1)\n",
    "           \n",
    "        # Estimate V using auto encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            Down(in_channels=1, out_channels=64),\n",
    "            Down(in_channels=64, out_channels=16),\n",
    "            OutConv(in_channels=16, out_channels=1),\n",
    "            )\n",
    "        self.fc1 = nn.Linear(25*25, 2*self.dz)\n",
    "        self.decoder = nn.Sequential(\n",
    "            DoubleConv(in_channels=self.dz+2, out_channels=64),\n",
    "            DoubleConv(in_channels=64, out_channels=16),\n",
    "            OutConv(in_channels=16, out_channels=1),\n",
    "            ) \n",
    "        self.im_size = im_size\n",
    "        x = torch.linspace(-1, 1, im_size)\n",
    "        y = torch.linspace(-1, 1, im_size)\n",
    "        x_grid, y_grid = torch.meshgrid(x, y)\n",
    "        # Add as constant, with extra dims for N and C\n",
    "        self.register_buffer('x_grid', x_grid.view((1, 1) + x_grid.shape))\n",
    "        self.register_buffer('y_grid', y_grid.view((1, 1) + y_grid.shape))\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, _, N, F = x.shape\n",
    "        z_all, v_all, h_all = [], [], []\n",
    "        I = x.shape[0]\n",
    "        \"Neural nets for H,V\"\n",
    "        shat_all = []\n",
    "        for i in range(self.K):\n",
    "            if i == 0:\n",
    "                inp = x\n",
    "            else:\n",
    "                tmp = hj[...,None]@W@inp.permute(2,3,0,1)[...,None]\n",
    "                inp = inp - tmp.squeeze().permute(2,3,0,1)\n",
    "\n",
    "            # sb = self.b2(self.b1(inp.abs()).squeeze()).mean(dim=1).exp()\n",
    "            # Rb = (sb[:None]*torch.ones(batch_size, self.M, \\\n",
    "            #     device=x.device)).diag_embed().to(torch.cfloat) # shape:[I, M, M]\n",
    "            Rb = (1.4e-3*torch.ones(batch_size, self.M, \\\n",
    "                device=x.device)).diag_embed().to(torch.cfloat) # shape:[I, M, M]\n",
    "            hj = hgt[:,i].repeat(I).reshape(I,3) # shape:[I, M]\n",
    "            h_all.append(hj)\n",
    "\n",
    "            \"Wienter filter to get coarse shat\"\n",
    "            Rx = hj[...,None] @ hj[:,None].conj() + Rb # shape of [I,M,M]\n",
    "            W = hj[:, None,].conj() @ Rx.inverse()  # shape of [N,F,I,1,M]\n",
    "            shat = (W @ inp.permute(2,3,0,1)[...,None]).squeeze().permute(2,0,1) #[I, N, F]\n",
    "            shat = shat/shat.detach().abs().max()\n",
    "            shat_all.append(shat)\n",
    "        \n",
    "        for i in range(self.K):\n",
    "            \"Encoder\"\n",
    "            xx = self.encoder(shat_all[i][:,None].abs())\n",
    "            \"Get latent variable\"\n",
    "            zz = self.fc1(xx.reshape(batch_size,-1))\n",
    "            mu = zz[:,::2]\n",
    "            logvar = zz[:,1::2]\n",
    "            z = self.reparameterize(mu, logvar)\n",
    "            z_all.append(z)\n",
    "            \n",
    "            \"Decoder to get V\"\n",
    "            # View z as 4D tensor to be tiled across new N and F dimensions            \n",
    "            zr = z.view((batch_size, self.dz)+ (1, 1))  #Shape: IxDxNxF\n",
    "            # Tile across to match image size\n",
    "            zr = zr.expand(-1, -1, self.im_size, self.im_size)  #Shape: IxDx64x64\n",
    "            # Expand grids to batches and concatenate on the channel dimension\n",
    "            zbd = torch.cat((self.x_grid.expand(batch_size, -1, -1, -1),\n",
    "                        self.y_grid.expand(batch_size, -1, -1, -1), zr), dim=1) # Shape: Ix(dz*K+2)xNxF\n",
    "            v = self.decoder(zbd).exp()\n",
    "            v_all.append(threshold(v, floor=1e-3, ceiling=1e2)) # 1e-3 to 1e2\n",
    "        Hhat = torch.stack(h_all, 2) # shape:[I, M, K]\n",
    "        vhat = torch.stack(v_all, 4).squeeze().to(torch.cfloat) # shape:[I, N, F, K]\n",
    "\n",
    "        return vhat.diag_embed(), Hhat, Rb, mu, logvar\n",
    "\n",
    "def loss_fun(x, Rs, Hhat, Rb, mu, logvar, beta=1e-2):\n",
    "    x = x.permute(0,2,3,1)\n",
    "    kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    Rxperm = Hhat @ Rs.permute(1,2,0,3,4) @ Hhat.transpose(-1,-2).conj() + Rb\n",
    "    Rx = Rxperm.permute(2,0,1,3,4) # shape of [I, N, F, M, M]\n",
    "    try:\n",
    "        ll = -(np.pi*mydet(Rx)).log() - (x[...,None,:].conj()@Rx.inverse()@x[...,None]).squeeze() \n",
    "    except:\n",
    "        torch.save((x, Rx, Rs, Hhat, Rb), f'rid{rid}x_Rx_Rs_Hhat_Rb.pt')\n",
    "        print('error happpened, data saved and stop')\n",
    "        ll = -(np.pi*mydet(Rx)).log() - (x[...,None,:].conj()@Rx.inverse()@x[...,None]).squeeze()\n",
    "    return -ll.sum().real, beta*kl\n",
    "\n",
    "#%%\n",
    "fig_loc = '../data/nem_ss/figures/'\n",
    "mod_loc = '../data/nem_ss/models/'\n",
    "if not(os.path.isdir(fig_loc + f'/{rid}/')): \n",
    "    print('made a new folder')\n",
    "    os.mkdir(fig_loc + f'{rid}/')\n",
    "    os.mkdir(mod_loc + f'{rid}/')\n",
    "fig_loc = fig_loc + f'{rid}/'\n",
    "mod_loc = mod_loc + f'{rid}/'\n",
    "\n",
    "I = 3000 # how many samples\n",
    "M, N, F, K = 3, 100, 100, 3\n",
    "NF = N*F\n",
    "eps = 5e-4\n",
    "opts = {}\n",
    "opts['batch_size'] = 64\n",
    "opts['lr'] = 1e-3\n",
    "opts['n_epochs'] = 150\n",
    "\n",
    "d = torch.load('../data/nem_ss/tr3kM3FT100.pt')\n",
    "d = awgn_batch(d, snr=30, seed=1)\n",
    "xtr = (d/d.abs().amax(dim=(1,2,3))[:,None,None,None]) # [sample,M,N,F]\n",
    "xtr = xtr.to(torch.cfloat)\n",
    "data = Data.TensorDataset(xtr[:I])\n",
    "tr = Data.DataLoader(data, batch_size=opts['batch_size'], shuffle=True, drop_last=True)\n",
    "xval, _ , hgt0 = torch.load('../data/nem_ss/val500M3FT100_xsh.pt')\n",
    "hgt = torch.tensor(hgt0).to(torch.cfloat).cuda()\n",
    "xval_cuda = xval[:128].to(torch.cfloat).cuda()\n",
    "\n",
    "loss_iter, loss_tr, loss1, loss2, loss_eval = [], [], [], [], []\n",
    "NN = NN_gtsbd\n",
    "model = NN(M,K,N).cuda()\n",
    "# for w in model.parameters():\n",
    "#     nn.init.normal_(w, mean=0., std=0.01)\n",
    "\n",
    "optimizer = RAdam(model.parameters(),\n",
    "                lr= opts['lr'],\n",
    "                betas=(0.9, 0.999), \n",
    "                eps=1e-8,\n",
    "                weight_decay=0)\n",
    "\n",
    "for epoch in range(opts['n_epochs']):\n",
    "    model.train()\n",
    "    for i, (x,) in enumerate(tr): \n",
    "        x = x.cuda()\n",
    "        optimizer.zero_grad()         \n",
    "        Rs, Hhat, Rb, mu, logvar= model(x)\n",
    "        l1, l2 = loss_fun(x, Rs, Hhat, Rb, mu, logvar)\n",
    "        loss = l1 + l2\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "        optimizer.step()\n",
    "        torch.cuda.empty_cache()\n",
    " \n",
    "    loss_tr.append(loss.detach().cpu().item()/opts['batch_size'])\n",
    "    loss1.append(l1.detach().cpu().item()/opts['batch_size'])\n",
    "    loss2.append(l2.detach().cpu().item()/opts['batch_size'])\n",
    "    if epoch%10 == 0:\n",
    "        plt.figure()\n",
    "        plt.plot(loss_tr, '-or')\n",
    "        plt.title(f'Loss fuction at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_LossFunAll')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss1, '-og')\n",
    "        plt.title(f'Reconstruction loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_Loss1')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss2, '-og')\n",
    "        plt.title(f'KL loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_Loss2')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss_tr[-50:], '-or')\n",
    "        plt.title(f'Last 50 of loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_last50')\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            Rs, Hhat, Rb, mu, logvar= model(xval_cuda)\n",
    "            l1, l2 = loss_fun(xval_cuda, Rs, Hhat, Rb, mu, logvar)\n",
    "            loss_eval.append((l1+l2).cpu().item()/128)\n",
    "            plt.figure()\n",
    "            plt.plot(loss_eval, '-xb')\n",
    "            plt.title(f'Accumulated validation loss at epoch{epoch}')\n",
    "            plt.savefig(fig_loc + f'Epoch{epoch}_val') \n",
    "            plt.close('all')           \n",
    "        torch.save(model, mod_loc+f'model_epoch{epoch}.pt')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% s2\n",
    "rid = 's2' # running id\n",
    "from math import ceil\n",
    "from utils import *\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "torch.set_printoptions(linewidth=160)\n",
    "from datetime import datetime\n",
    "print('starting date time ', datetime.now())\n",
    "torch.manual_seed(1)\n",
    "\n",
    "if torch.__version__[:5] != '1.8.1':\n",
    "    def mydet(x):\n",
    "        return x.det()\n",
    "    RAdam = torch.optim.RAdam\n",
    "else:\n",
    "    RAdam = optim.RAdam\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "from vae_model import *\n",
    "class NN_gtsbd(nn.Module):\n",
    "    \"\"\"This is recursive Wiener filter version, with Rb threshold of [1e-3, 1e2]\n",
    "    Input shape [I,M,N,F], e.g.[32,3,100,100]\n",
    "    J <=K\n",
    "    \"\"\"\n",
    "    def __init__(self, M=3, K=3, im_size=100):\n",
    "        super().__init__()\n",
    "        self.dz = 32\n",
    "        self.K, self.M = K, M\n",
    "\n",
    "        # Estimate H and coarse V\n",
    "        # self.est = nn.Sequential(\n",
    "        #     Down(in_channels=M*2, out_channels=64),\n",
    "        #     Down(in_channels=64, out_channels=32),\n",
    "        #     Down(in_channels=32, out_channels=4),\n",
    "        #     Reshape(-1, 4*12*12),\n",
    "        #     LinearBlock(4*12*12, 64),\n",
    "        #     nn.Linear(64, 1),\n",
    "        #     )\n",
    "        # self.b1 = nn.Linear(100, 1)\n",
    "        # self.b2 = nn.Linear(100, 1)\n",
    "           \n",
    "        # Estimate V using auto encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            Down(in_channels=1, out_channels=64),\n",
    "            Down(in_channels=64, out_channels=16),\n",
    "            OutConv(in_channels=16, out_channels=1),\n",
    "            )\n",
    "        self.fc1 = nn.Linear(25*25, 2*self.dz)\n",
    "        self.decoder = nn.Sequential(\n",
    "            DoubleConv(in_channels=self.dz+2, out_channels=64),\n",
    "            DoubleConv(in_channels=64, out_channels=16),\n",
    "            OutConv(in_channels=16, out_channels=1),\n",
    "            ) \n",
    "        self.im_size = im_size\n",
    "        x = torch.linspace(-1, 1, im_size)\n",
    "        y = torch.linspace(-1, 1, im_size)\n",
    "        x_grid, y_grid = torch.meshgrid(x, y)\n",
    "        # Add as constant, with extra dims for N and C\n",
    "        self.register_buffer('x_grid', x_grid.view((1, 1) + x_grid.shape))\n",
    "        self.register_buffer('y_grid', y_grid.view((1, 1) + y_grid.shape))\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, _, N, F = x.shape\n",
    "        z_all, v_all, h_all = [], [], []\n",
    "        I = x.shape[0]\n",
    "        \"Neural nets for H,V\"\n",
    "        shat_all = []\n",
    "        for i in range(self.K):\n",
    "            if i == 0:\n",
    "                inp = x\n",
    "            else:\n",
    "                tmp = hj[...,None]@W@inp.permute(2,3,0,1)[...,None]\n",
    "                inp = inp - tmp.squeeze().permute(2,3,0,1)\n",
    "\n",
    "            # sb = self.b2(self.b1(inp.abs()).squeeze()).mean(dim=1).exp()\n",
    "            # Rb = (sb[:None]*torch.ones(batch_size, self.M, \\\n",
    "            #     device=x.device)).diag_embed().to(torch.cfloat) # shape:[I, M, M]\n",
    "            Rb = (1.4e-3*torch.ones(batch_size, self.M, \\\n",
    "                device=x.device)).diag_embed().to(torch.cfloat) # shape:[I, M, M]\n",
    "            hj = hgt[:,i].repeat(I).reshape(I,3) # shape:[I, M]\n",
    "            h_all.append(hj)\n",
    "\n",
    "            \"Wienter filter to get coarse shat\"\n",
    "            Rx = hj[...,None] @ hj[:,None].conj() + Rb # shape of [I,M,M]\n",
    "            W = hj[:, None,].conj() @ Rx.inverse()  # shape of [N,F,I,1,M]\n",
    "            shat = (W @ inp.permute(2,3,0,1)[...,None]).squeeze().permute(2,0,1) #[I, N, F]\n",
    "            shat = shat/shat.detach().abs().max()\n",
    "            shat_all.append(shat)\n",
    "        \n",
    "        for i in range(self.K):\n",
    "            \"Encoder\"\n",
    "            xx = self.encoder(shat_all[i][:,None].abs())\n",
    "            \"Get latent variable\"\n",
    "            zz = self.fc1(xx.reshape(batch_size,-1))\n",
    "            mu = zz[:,::2]\n",
    "            logvar = zz[:,1::2]\n",
    "            z = self.reparameterize(mu, logvar)\n",
    "            z_all.append(z)\n",
    "            \n",
    "            \"Decoder to get V\"\n",
    "            # View z as 4D tensor to be tiled across new N and F dimensions            \n",
    "            zr = z.view((batch_size, self.dz)+ (1, 1))  #Shape: IxDxNxF\n",
    "            # Tile across to match image size\n",
    "            zr = zr.expand(-1, -1, self.im_size, self.im_size)  #Shape: IxDx64x64\n",
    "            # Expand grids to batches and concatenate on the channel dimension\n",
    "            zbd = torch.cat((self.x_grid.expand(batch_size, -1, -1, -1),\n",
    "                        self.y_grid.expand(batch_size, -1, -1, -1), zr), dim=1) # Shape: Ix(dz*K+2)xNxF\n",
    "            v = self.decoder(zbd).exp()\n",
    "            v_all.append(threshold(v, floor=1e-3, ceiling=1e2)) # 1e-3 to 1e2\n",
    "        Hhat = torch.stack(h_all, 2) # shape:[I, M, K]\n",
    "        vhat = torch.stack(v_all, 4).squeeze().to(torch.cfloat) # shape:[I, N, F, K]\n",
    "\n",
    "        return vhat.diag_embed(), Hhat, Rb, mu, logvar\n",
    "\n",
    "def loss_fun(x, Rs, Hhat, Rb, mu, logvar, beta=0.1):\n",
    "    x = x.permute(0,2,3,1)\n",
    "    kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    Rxperm = Hhat @ Rs.permute(1,2,0,3,4) @ Hhat.transpose(-1,-2).conj() + Rb\n",
    "    Rx = Rxperm.permute(2,0,1,3,4) # shape of [I, N, F, M, M]\n",
    "    try:\n",
    "        ll = -(np.pi*mydet(Rx)).log() - (x[...,None,:].conj()@Rx.inverse()@x[...,None]).squeeze() \n",
    "    except:\n",
    "        torch.save((x, Rx, Rs, Hhat, Rb), f'rid{rid}x_Rx_Rs_Hhat_Rb.pt')\n",
    "        print('error happpened, data saved and stop')\n",
    "        ll = -(np.pi*mydet(Rx)).log() - (x[...,None,:].conj()@Rx.inverse()@x[...,None]).squeeze()\n",
    "    return -ll.sum().real, beta*kl\n",
    "\n",
    "#%%\n",
    "fig_loc = '../data/nem_ss/figures/'\n",
    "mod_loc = '../data/nem_ss/models/'\n",
    "if not(os.path.isdir(fig_loc + f'/{rid}/')): \n",
    "    print('made a new folder')\n",
    "    os.mkdir(fig_loc + f'{rid}/')\n",
    "    os.mkdir(mod_loc + f'{rid}/')\n",
    "fig_loc = fig_loc + f'{rid}/'\n",
    "mod_loc = mod_loc + f'{rid}/'\n",
    "\n",
    "I = 3000 # how many samples\n",
    "M, N, F, K = 3, 100, 100, 3\n",
    "NF = N*F\n",
    "eps = 5e-4\n",
    "opts = {}\n",
    "opts['batch_size'] = 64\n",
    "opts['lr'] = 1e-3\n",
    "opts['n_epochs'] = 150\n",
    "\n",
    "d = torch.load('../data/nem_ss/tr3kM3FT100.pt')\n",
    "d = awgn_batch(d, snr=30, seed=1)\n",
    "xtr = (d/d.abs().amax(dim=(1,2,3))[:,None,None,None]) # [sample,M,N,F]\n",
    "xtr = xtr.to(torch.cfloat)\n",
    "data = Data.TensorDataset(xtr[:I])\n",
    "tr = Data.DataLoader(data, batch_size=opts['batch_size'], shuffle=True, drop_last=True)\n",
    "xval, _ , hgt0 = torch.load('../data/nem_ss/val500M3FT100_xsh.pt')\n",
    "hgt = torch.tensor(hgt0).to(torch.cfloat).cuda()\n",
    "xval_cuda = xval[:128].to(torch.cfloat).cuda()\n",
    "\n",
    "loss_iter, loss_tr, loss1, loss2, loss_eval = [], [], [], [], []\n",
    "NN = NN_gtsbd\n",
    "model = NN(M,K,N).cuda()\n",
    "# for w in model.parameters():\n",
    "#     nn.init.normal_(w, mean=0., std=0.01)\n",
    "\n",
    "optimizer = RAdam(model.parameters(),\n",
    "                lr= opts['lr'],\n",
    "                betas=(0.9, 0.999), \n",
    "                eps=1e-8,\n",
    "                weight_decay=0)\n",
    "\n",
    "for epoch in range(opts['n_epochs']):\n",
    "    model.train()\n",
    "    for i, (x,) in enumerate(tr): \n",
    "        x = x.cuda()\n",
    "        optimizer.zero_grad()         \n",
    "        Rs, Hhat, Rb, mu, logvar= model(x)\n",
    "        l1, l2 = loss_fun(x, Rs, Hhat, Rb, mu, logvar)\n",
    "        loss = l1 + l2\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "        optimizer.step()\n",
    "        torch.cuda.empty_cache()\n",
    " \n",
    "    loss_tr.append(loss.detach().cpu().item()/opts['batch_size'])\n",
    "    loss1.append(l1.detach().cpu().item()/opts['batch_size'])\n",
    "    loss2.append(l2.detach().cpu().item()/opts['batch_size'])\n",
    "    if epoch%10 == 0:\n",
    "        plt.figure()\n",
    "        plt.plot(loss_tr, '-or')\n",
    "        plt.title(f'Loss fuction at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_LossFunAll')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss1, '-og')\n",
    "        plt.title(f'Reconstruction loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_Loss1')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss2, '-og')\n",
    "        plt.title(f'KL loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_Loss2')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss_tr[-50:], '-or')\n",
    "        plt.title(f'Last 50 of loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_last50')\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            Rs, Hhat, Rb, mu, logvar= model(xval_cuda)\n",
    "            l1, l2 = loss_fun(xval_cuda, Rs, Hhat, Rb, mu, logvar)\n",
    "            loss_eval.append((l1+l2).cpu().item()/128)\n",
    "            plt.figure()\n",
    "            plt.plot(loss_eval, '-xb')\n",
    "            plt.title(f'Accumulated validation loss at epoch{epoch}')\n",
    "            plt.savefig(fig_loc + f'Epoch{epoch}_val') \n",
    "            plt.close('all')           \n",
    "        torch.save(model, mod_loc+f'model_epoch{epoch}.pt')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% s3\n",
    "rid = 's3' # running id\n",
    "from math import ceil\n",
    "from utils import *\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "torch.set_printoptions(linewidth=160)\n",
    "from datetime import datetime\n",
    "print('starting date time ', datetime.now())\n",
    "torch.manual_seed(1)\n",
    "\n",
    "if torch.__version__[:5] != '1.8.1':\n",
    "    def mydet(x):\n",
    "        return x.det()\n",
    "    RAdam = torch.optim.RAdam\n",
    "else:\n",
    "    RAdam = optim.RAdam\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "from vae_model import *\n",
    "class NN_gtsbd(nn.Module):\n",
    "    \"\"\"This is recursive Wiener filter version, with Rb threshold of [1e-3, 1e2]\n",
    "    Input shape [I,M,N,F], e.g.[32,3,100,100]\n",
    "    J <=K\n",
    "    \"\"\"\n",
    "    def __init__(self, M=3, K=3, im_size=100):\n",
    "        super().__init__()\n",
    "        self.dz = 32\n",
    "        self.K, self.M = K, M\n",
    "\n",
    "        # Estimate H and coarse V\n",
    "        # self.est = nn.Sequential(\n",
    "        #     Down(in_channels=M*2, out_channels=64),\n",
    "        #     Down(in_channels=64, out_channels=32),\n",
    "        #     Down(in_channels=32, out_channels=4),\n",
    "        #     Reshape(-1, 4*12*12),\n",
    "        #     LinearBlock(4*12*12, 64),\n",
    "        #     nn.Linear(64, 1),\n",
    "        #     )\n",
    "        # self.b1 = nn.Linear(100, 1)\n",
    "        # self.b2 = nn.Linear(100, 1)\n",
    "           \n",
    "        # Estimate V using auto encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            Down(in_channels=1, out_channels=64),\n",
    "            Down(in_channels=64, out_channels=16),\n",
    "            OutConv(in_channels=16, out_channels=1),\n",
    "            )\n",
    "        self.fc1 = nn.Linear(25*25, 2*self.dz)\n",
    "        self.decoder = nn.Sequential(\n",
    "            DoubleConv(in_channels=self.dz+2, out_channels=64),\n",
    "            DoubleConv(in_channels=64, out_channels=16),\n",
    "            OutConv(in_channels=16, out_channels=1),\n",
    "            ) \n",
    "        self.im_size = im_size\n",
    "        x = torch.linspace(-1, 1, im_size)\n",
    "        y = torch.linspace(-1, 1, im_size)\n",
    "        x_grid, y_grid = torch.meshgrid(x, y)\n",
    "        # Add as constant, with extra dims for N and C\n",
    "        self.register_buffer('x_grid', x_grid.view((1, 1) + x_grid.shape))\n",
    "        self.register_buffer('y_grid', y_grid.view((1, 1) + y_grid.shape))\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, _, N, F = x.shape\n",
    "        z_all, v_all, h_all = [], [], []\n",
    "        I = x.shape[0]\n",
    "        \"Neural nets for H,V\"\n",
    "        shat_all = []\n",
    "        for i in range(self.K):\n",
    "            if i == 0:\n",
    "                inp = x\n",
    "            else:\n",
    "                tmp = hj[...,None]@W@inp.permute(2,3,0,1)[...,None]\n",
    "                inp = inp - tmp.squeeze().permute(2,3,0,1)\n",
    "\n",
    "            # sb = self.b2(self.b1(inp.abs()).squeeze()).mean(dim=1).exp()\n",
    "            # Rb = (sb[:None]*torch.ones(batch_size, self.M, \\\n",
    "            #     device=x.device)).diag_embed().to(torch.cfloat) # shape:[I, M, M]\n",
    "            Rb = (1.4e-3*torch.ones(batch_size, self.M, \\\n",
    "                device=x.device)).diag_embed().to(torch.cfloat) # shape:[I, M, M]\n",
    "            hj = hgt[:,i].repeat(I).reshape(I,3) # shape:[I, M]\n",
    "            h_all.append(hj)\n",
    "\n",
    "            \"Wienter filter to get coarse shat\"\n",
    "            Rx = hj[...,None] @ hj[:,None].conj() + Rb # shape of [I,M,M]\n",
    "            W = hj[:, None,].conj() @ Rx.inverse()  # shape of [N,F,I,1,M]\n",
    "            shat = (W @ inp.permute(2,3,0,1)[...,None]).squeeze().permute(2,0,1) #[I, N, F]\n",
    "            shat = shat/shat.detach().abs().max()\n",
    "            shat_all.append(shat)\n",
    "        \n",
    "        for i in range(self.K):\n",
    "            \"Encoder\"\n",
    "            xx = self.encoder(shat_all[i][:,None].abs())\n",
    "            \"Get latent variable\"\n",
    "            zz = self.fc1(xx.reshape(batch_size,-1))\n",
    "            mu = zz[:,::2]\n",
    "            logvar = zz[:,1::2]\n",
    "            z = self.reparameterize(mu, logvar)\n",
    "            z_all.append(z)\n",
    "            \n",
    "            \"Decoder to get V\"\n",
    "            # View z as 4D tensor to be tiled across new N and F dimensions            \n",
    "            zr = z.view((batch_size, self.dz)+ (1, 1))  #Shape: IxDxNxF\n",
    "            # Tile across to match image size\n",
    "            zr = zr.expand(-1, -1, self.im_size, self.im_size)  #Shape: IxDx64x64\n",
    "            # Expand grids to batches and concatenate on the channel dimension\n",
    "            zbd = torch.cat((self.x_grid.expand(batch_size, -1, -1, -1),\n",
    "                        self.y_grid.expand(batch_size, -1, -1, -1), zr), dim=1) # Shape: Ix(dz*K+2)xNxF\n",
    "            v = self.decoder(zbd).exp()\n",
    "            v_all.append(threshold(v, floor=1e-3, ceiling=1e2)) # 1e-3 to 1e2\n",
    "        Hhat = torch.stack(h_all, 2) # shape:[I, M, K]\n",
    "        vhat = torch.stack(v_all, 4).squeeze().to(torch.cfloat) # shape:[I, N, F, K]\n",
    "\n",
    "        return vhat.diag_embed(), Hhat, Rb, mu, logvar\n",
    "\n",
    "def loss_fun(x, Rs, Hhat, Rb, mu, logvar, beta=1):\n",
    "    x = x.permute(0,2,3,1)\n",
    "    kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    Rxperm = Hhat @ Rs.permute(1,2,0,3,4) @ Hhat.transpose(-1,-2).conj() + Rb\n",
    "    Rx = Rxperm.permute(2,0,1,3,4) # shape of [I, N, F, M, M]\n",
    "    try:\n",
    "        ll = -(np.pi*mydet(Rx)).log() - (x[...,None,:].conj()@Rx.inverse()@x[...,None]).squeeze() \n",
    "    except:\n",
    "        torch.save((x, Rx, Rs, Hhat, Rb), f'rid{rid}x_Rx_Rs_Hhat_Rb.pt')\n",
    "        print('error happpened, data saved and stop')\n",
    "        ll = -(np.pi*mydet(Rx)).log() - (x[...,None,:].conj()@Rx.inverse()@x[...,None]).squeeze()\n",
    "    return -ll.sum().real, beta*kl\n",
    "\n",
    "#%%\n",
    "fig_loc = '../data/nem_ss/figures/'\n",
    "mod_loc = '../data/nem_ss/models/'\n",
    "if not(os.path.isdir(fig_loc + f'/{rid}/')): \n",
    "    print('made a new folder')\n",
    "    os.mkdir(fig_loc + f'{rid}/')\n",
    "    os.mkdir(mod_loc + f'{rid}/')\n",
    "fig_loc = fig_loc + f'{rid}/'\n",
    "mod_loc = mod_loc + f'{rid}/'\n",
    "\n",
    "I = 3000 # how many samples\n",
    "M, N, F, K = 3, 100, 100, 3\n",
    "NF = N*F\n",
    "eps = 5e-4\n",
    "opts = {}\n",
    "opts['batch_size'] = 64\n",
    "opts['lr'] = 1e-3\n",
    "opts['n_epochs'] = 150\n",
    "\n",
    "d = torch.load('../data/nem_ss/tr3kM3FT100.pt')\n",
    "d = awgn_batch(d, snr=30, seed=1)\n",
    "xtr = (d/d.abs().amax(dim=(1,2,3))[:,None,None,None]) # [sample,M,N,F]\n",
    "xtr = xtr.to(torch.cfloat)\n",
    "data = Data.TensorDataset(xtr[:I])\n",
    "tr = Data.DataLoader(data, batch_size=opts['batch_size'], shuffle=True, drop_last=True)\n",
    "xval, _ , hgt0 = torch.load('../data/nem_ss/val500M3FT100_xsh.pt')\n",
    "hgt = torch.tensor(hgt0).to(torch.cfloat).cuda()\n",
    "xval_cuda = xval[:128].to(torch.cfloat).cuda()\n",
    "\n",
    "loss_iter, loss_tr, loss1, loss2, loss_eval = [], [], [], [], []\n",
    "NN = NN_gtsbd\n",
    "model = NN(M,K,N).cuda()\n",
    "# for w in model.parameters():\n",
    "#     nn.init.normal_(w, mean=0., std=0.01)\n",
    "\n",
    "optimizer = RAdam(model.parameters(),\n",
    "                lr= opts['lr'],\n",
    "                betas=(0.9, 0.999), \n",
    "                eps=1e-8,\n",
    "                weight_decay=0)\n",
    "\n",
    "for epoch in range(opts['n_epochs']):\n",
    "    model.train()\n",
    "    for i, (x,) in enumerate(tr): \n",
    "        x = x.cuda()\n",
    "        optimizer.zero_grad()         \n",
    "        Rs, Hhat, Rb, mu, logvar= model(x)\n",
    "        l1, l2 = loss_fun(x, Rs, Hhat, Rb, mu, logvar)\n",
    "        loss = l1 + l2\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "        optimizer.step()\n",
    "        torch.cuda.empty_cache()\n",
    " \n",
    "    loss_tr.append(loss.detach().cpu().item()/opts['batch_size'])\n",
    "    loss1.append(l1.detach().cpu().item()/opts['batch_size'])\n",
    "    loss2.append(l2.detach().cpu().item()/opts['batch_size'])\n",
    "    if epoch%10 == 0:\n",
    "        plt.figure()\n",
    "        plt.plot(loss_tr, '-or')\n",
    "        plt.title(f'Loss fuction at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_LossFunAll')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss1, '-og')\n",
    "        plt.title(f'Reconstruction loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_Loss1')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss2, '-og')\n",
    "        plt.title(f'KL loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_Loss2')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss_tr[-50:], '-or')\n",
    "        plt.title(f'Last 50 of loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_last50')\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            Rs, Hhat, Rb, mu, logvar= model(xval_cuda)\n",
    "            l1, l2 = loss_fun(xval_cuda, Rs, Hhat, Rb, mu, logvar)\n",
    "            loss_eval.append((l1+l2).cpu().item()/128)\n",
    "            plt.figure()\n",
    "            plt.plot(loss_eval, '-xb')\n",
    "            plt.title(f'Accumulated validation loss at epoch{epoch}')\n",
    "            plt.savefig(fig_loc + f'Epoch{epoch}_val') \n",
    "            plt.close('all')           \n",
    "        torch.save(model, mod_loc+f'model_epoch{epoch}.pt')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% s4\n",
    "rid = 's4' # running id\n",
    "from utils import *\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "torch.set_printoptions(linewidth=160)\n",
    "from datetime import datetime\n",
    "print('starting date time ', datetime.now())\n",
    "torch.manual_seed(1)\n",
    "\n",
    "if torch.__version__[:5] != '1.8.1':\n",
    "    def mydet(x):\n",
    "        return x.det()\n",
    "    RAdam = torch.optim.RAdam\n",
    "else:\n",
    "    RAdam = optim.RAdam\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "from vae_model import *\n",
    "class NN_gtupconv(nn.Module):\n",
    "    \"\"\"This is recursive Wiener filter version, with Rb threshold of [1e-3, 1e2]\n",
    "    Input shape [I,M,N,F], e.g.[32,3,100,100]\n",
    "    J <=K\n",
    "    \"\"\"\n",
    "    def __init__(self, M=3, K=3, im_size=100):\n",
    "        super().__init__()\n",
    "        self.dz = 32\n",
    "        self.K, self.M = K, M\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            Down(in_channels=1, out_channels=64),\n",
    "            DoubleConv(in_channels=64, out_channels=32),\n",
    "            Down(in_channels=32, out_channels=16),\n",
    "            DoubleConv(in_channels=16, out_channels=1),\n",
    "            )\n",
    "        self.fc1 = nn.Linear(25*25, 2*self.dz)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(self.dz, 25*25),\n",
    "            Reshape(-1, 1, 25, 25),\n",
    "            Up_(in_channels=1, out_channels=64),\n",
    "            DoubleConv(in_channels=64, out_channels=32),\n",
    "            Up_(in_channels=32, out_channels=16),\n",
    "            DoubleConv(in_channels=16, out_channels=4),\n",
    "            OutConv(in_channels=4, out_channels=1),\n",
    "            ) \n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, _, N, F = x.shape\n",
    "        z_all, v_all, h_all = [], [], []\n",
    "        I = x.shape[0]\n",
    "        \"Neural nets for H,V\"\n",
    "        shat_all = []\n",
    "        for i in range(self.K):\n",
    "            if i == 0:\n",
    "                inp = x\n",
    "            else:\n",
    "                tmp = hj[...,None]@W@inp.permute(2,3,0,1)[...,None]\n",
    "                inp = inp - tmp.squeeze().permute(2,3,0,1)\n",
    "\n",
    "            # sb = self.b2(self.b1(inp.abs()).squeeze()).mean(dim=1).exp()\n",
    "            # Rb = (sb[:None]*torch.ones(batch_size, self.M, \\\n",
    "            #     device=x.device)).diag_embed().to(torch.cfloat) # shape:[I, M, M]\n",
    "            Rb = (1.4e-3*torch.ones(batch_size, self.M, \\\n",
    "                device=x.device)).diag_embed().to(torch.cfloat) # shape:[I, M, M]\n",
    "            hj = hgt[:,i].repeat(I).reshape(I,3) # shape:[I, M]\n",
    "            h_all.append(hj)\n",
    "\n",
    "            \"Wienter filter to get coarse shat\"\n",
    "            Rx = hj[...,None] @ hj[:,None].conj() + Rb # shape of [I,M,M]\n",
    "            W = hj[:, None,].conj() @ Rx.inverse()  # shape of [N,F,I,1,M]\n",
    "            shat = (W @ inp.permute(2,3,0,1)[...,None]).squeeze().permute(2,0,1) #[I, N, F]\n",
    "            shat = shat/shat.detach().abs().max()\n",
    "            shat_all.append(shat)\n",
    "        \n",
    "        for i in range(self.K):\n",
    "            \"Encoder\"\n",
    "            xx = self.encoder(shat[:,None].abs())\n",
    "            \"Get latent variable\"\n",
    "            zz = self.fc1(xx.reshape(batch_size,-1))\n",
    "            mu = zz[:,::2]\n",
    "            logvar = zz[:,1::2]\n",
    "            z = self.reparameterize(mu, logvar)\n",
    "            z_all.append(z)\n",
    "            \n",
    "            \"Decoder to get V\"\n",
    "            v = self.decoder(z).exp()\n",
    "            v_all.append(threshold(v, floor=1e-3, ceiling=1e2)) # 1e-3 to 1e2\n",
    "        Hhat = torch.stack(h_all, 2) # shape:[I, M, K]\n",
    "        vhat = torch.stack(v_all, 4).squeeze().to(torch.cfloat) # shape:[I, N, F, K]\n",
    "\n",
    "        return vhat.diag_embed(), Hhat, Rb, mu, logvar\n",
    "\n",
    "def loss_fun(x, Rs, Hhat, Rb, mu, logvar, beta=1e-3):\n",
    "    x = x.permute(0,2,3,1)\n",
    "    kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    Rxperm = Hhat @ Rs.permute(1,2,0,3,4) @ Hhat.transpose(-1,-2).conj() + Rb\n",
    "    Rx = Rxperm.permute(2,0,1,3,4) # shape of [I, N, F, M, M]\n",
    "    try:\n",
    "        ll = -(np.pi*mydet(Rx)).log() - (x[...,None,:].conj()@Rx.inverse()@x[...,None]).squeeze() \n",
    "    except:\n",
    "        torch.save((x, Rx, Rs, Hhat, Rb), f'rid{rid}x_Rx_Rs_Hhat_Rb.pt')\n",
    "        print('error happpened, data saved and stop')\n",
    "        ll = -(np.pi*mydet(Rx)).log() - (x[...,None,:].conj()@Rx.inverse()@x[...,None]).squeeze()\n",
    "    return -ll.sum().real, beta*kl\n",
    "\n",
    "#%%\n",
    "fig_loc = '../data/nem_ss/figures/'\n",
    "mod_loc = '../data/nem_ss/models/'\n",
    "if not(os.path.isdir(fig_loc + f'/{rid}/')): \n",
    "    print('made a new folder')\n",
    "    os.mkdir(fig_loc + f'{rid}/')\n",
    "    os.mkdir(mod_loc + f'{rid}/')\n",
    "fig_loc = fig_loc + f'{rid}/'\n",
    "mod_loc = mod_loc + f'{rid}/'\n",
    "\n",
    "I = 3000 # how many samples\n",
    "M, N, F, K = 3, 100, 100, 3\n",
    "NF = N*F\n",
    "eps = 5e-4\n",
    "opts = {}\n",
    "opts['batch_size'] = 64\n",
    "opts['lr'] = 1e-3\n",
    "opts['n_epochs'] = 150\n",
    "\n",
    "d = torch.load('../data/nem_ss/tr3kM3FT100.pt')\n",
    "d = awgn_batch(d, snr=30, seed=1)\n",
    "xtr = (d/d.abs().amax(dim=(1,2,3))[:,None,None,None]) # [sample,M,N,F]\n",
    "xtr = xtr.to(torch.cfloat)\n",
    "data = Data.TensorDataset(xtr[:I])\n",
    "tr = Data.DataLoader(data, batch_size=opts['batch_size'], shuffle=True, drop_last=True)\n",
    "xval, _ , hgt0 = torch.load('../data/nem_ss/val500M3FT100_xsh.pt')\n",
    "hgt = torch.tensor(hgt0).to(torch.cfloat).cuda()\n",
    "xval_cuda = xval[:128].to(torch.cfloat).cuda()\n",
    "\n",
    "loss_iter, loss_tr, loss1, loss2, loss_eval = [], [], [], [], []\n",
    "NN = NN_gtupconv\n",
    "model = NN(M,K,N).cuda()\n",
    "# for w in model.parameters():\n",
    "#     nn.init.normal_(w, mean=0., std=0.01)\n",
    "\n",
    "optimizer = RAdam(model.parameters(),\n",
    "                lr= opts['lr'],\n",
    "                betas=(0.9, 0.999), \n",
    "                eps=1e-8,\n",
    "                weight_decay=0)\n",
    "\n",
    "for epoch in range(opts['n_epochs']):\n",
    "    model.train()\n",
    "    for i, (x,) in enumerate(tr): \n",
    "        x = x.cuda()\n",
    "        optimizer.zero_grad()         \n",
    "        Rs, Hhat, Rb, mu, logvar= model(x)\n",
    "        l1, l2 = loss_fun(x, Rs, Hhat, Rb, mu, logvar)\n",
    "        loss = l1 + l2\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "        optimizer.step()\n",
    "        torch.cuda.empty_cache()\n",
    " \n",
    "    loss_tr.append(loss.detach().cpu().item()/opts['batch_size'])\n",
    "    loss1.append(l1.detach().cpu().item()/opts['batch_size'])\n",
    "    loss2.append(l2.detach().cpu().item()/opts['batch_size'])\n",
    "    if epoch%10 == 0:\n",
    "        print(epoch)\n",
    "        plt.figure()\n",
    "        plt.plot(loss_tr, '-or')\n",
    "        plt.title(f'Loss fuction at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_LossFunAll')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss1, '-og')\n",
    "        plt.title(f'Reconstruction loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_Loss1')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss2, '-og')\n",
    "        plt.title(f'KL loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_Loss2')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss_tr[-50:], '-or')\n",
    "        plt.title(f'Last 50 of loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_last50')\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            Rs, Hhat, Rb, mu, logvar= model(xval_cuda)\n",
    "            l1, l2 = loss_fun(xval_cuda, Rs, Hhat, Rb, mu, logvar)\n",
    "            loss_eval.append((l1+l2).cpu().item()/128)\n",
    "            plt.figure()\n",
    "            plt.plot(loss_eval, '-xb')\n",
    "            plt.title(f'Accumulated validation loss at epoch{epoch}')\n",
    "            plt.savefig(fig_loc + f'Epoch{epoch}_val') \n",
    "            plt.close('all')           \n",
    "        torch.save(model, mod_loc+f'model_epoch{epoch}.pt')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% s5\n",
    "rid = 's5' # running id\n",
    "from utils import *\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "torch.set_printoptions(linewidth=160)\n",
    "from datetime import datetime\n",
    "print('starting date time ', datetime.now())\n",
    "torch.manual_seed(1)\n",
    "\n",
    "if torch.__version__[:5] != '1.8.1':\n",
    "    def mydet(x):\n",
    "        return x.det()\n",
    "    RAdam = torch.optim.RAdam\n",
    "else:\n",
    "    RAdam = optim.RAdam\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "from vae_model import *\n",
    "class NN_gtupconv(nn.Module):\n",
    "    \"\"\"This is recursive Wiener filter version, with Rb threshold of [1e-3, 1e2]\n",
    "    Input shape [I,M,N,F], e.g.[32,3,100,100]\n",
    "    J <=K\n",
    "    \"\"\"\n",
    "    def __init__(self, M=3, K=3, im_size=100):\n",
    "        super().__init__()\n",
    "        self.dz = 32\n",
    "        self.K, self.M = K, M\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            Down(in_channels=1, out_channels=64),\n",
    "            DoubleConv(in_channels=64, out_channels=32),\n",
    "            Down(in_channels=32, out_channels=16),\n",
    "            DoubleConv(in_channels=16, out_channels=1),\n",
    "            )\n",
    "        self.fc1 = nn.Linear(25*25, 2*self.dz)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(self.dz, 25*25),\n",
    "            Reshape(-1, 1, 25, 25),\n",
    "            Up_(in_channels=1, out_channels=64),\n",
    "            DoubleConv(in_channels=64, out_channels=32),\n",
    "            Up_(in_channels=32, out_channels=16),\n",
    "            DoubleConv(in_channels=16, out_channels=4),\n",
    "            OutConv(in_channels=4, out_channels=1),\n",
    "            ) \n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, _, N, F = x.shape\n",
    "        z_all, v_all, h_all = [], [], []\n",
    "        I = x.shape[0]\n",
    "        \"Neural nets for H,V\"\n",
    "        shat_all = []\n",
    "        for i in range(self.K):\n",
    "            if i == 0:\n",
    "                inp = x\n",
    "            else:\n",
    "                tmp = hj[...,None]@W@inp.permute(2,3,0,1)[...,None]\n",
    "                inp = inp - tmp.squeeze().permute(2,3,0,1)\n",
    "\n",
    "            # sb = self.b2(self.b1(inp.abs()).squeeze()).mean(dim=1).exp()\n",
    "            # Rb = (sb[:None]*torch.ones(batch_size, self.M, \\\n",
    "            #     device=x.device)).diag_embed().to(torch.cfloat) # shape:[I, M, M]\n",
    "            Rb = (1.4e-3*torch.ones(batch_size, self.M, \\\n",
    "                device=x.device)).diag_embed().to(torch.cfloat) # shape:[I, M, M]\n",
    "            hj = hgt[:,i].repeat(I).reshape(I,3) # shape:[I, M]\n",
    "            h_all.append(hj)\n",
    "\n",
    "            \"Wienter filter to get coarse shat\"\n",
    "            Rx = hj[...,None] @ hj[:,None].conj() + Rb # shape of [I,M,M]\n",
    "            W = hj[:, None,].conj() @ Rx.inverse()  # shape of [N,F,I,1,M]\n",
    "            shat = (W @ inp.permute(2,3,0,1)[...,None]).squeeze().permute(2,0,1) #[I, N, F]\n",
    "            shat = shat/shat.detach().abs().max()\n",
    "            shat_all.append(shat)\n",
    "        \n",
    "        for i in range(self.K):\n",
    "            \"Encoder\"\n",
    "            xx = self.encoder(shat[:,None].abs())\n",
    "            \"Get latent variable\"\n",
    "            zz = self.fc1(xx.reshape(batch_size,-1))\n",
    "            mu = zz[:,::2]\n",
    "            logvar = zz[:,1::2]\n",
    "            z = self.reparameterize(mu, logvar)\n",
    "            z_all.append(z)\n",
    "            \n",
    "            \"Decoder to get V\"\n",
    "            v = self.decoder(z).exp()\n",
    "            v_all.append(threshold(v, floor=1e-3, ceiling=1e2)) # 1e-3 to 1e2\n",
    "        Hhat = torch.stack(h_all, 2) # shape:[I, M, K]\n",
    "        vhat = torch.stack(v_all, 4).squeeze().to(torch.cfloat) # shape:[I, N, F, K]\n",
    "\n",
    "        return vhat.diag_embed(), Hhat, Rb, mu, logvar\n",
    "\n",
    "def loss_fun(x, Rs, Hhat, Rb, mu, logvar, beta=1e-2):\n",
    "    x = x.permute(0,2,3,1)\n",
    "    kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    Rxperm = Hhat @ Rs.permute(1,2,0,3,4) @ Hhat.transpose(-1,-2).conj() + Rb\n",
    "    Rx = Rxperm.permute(2,0,1,3,4) # shape of [I, N, F, M, M]\n",
    "    try:\n",
    "        ll = -(np.pi*mydet(Rx)).log() - (x[...,None,:].conj()@Rx.inverse()@x[...,None]).squeeze() \n",
    "    except:\n",
    "        torch.save((x, Rx, Rs, Hhat, Rb), f'rid{rid}x_Rx_Rs_Hhat_Rb.pt')\n",
    "        print('error happpened, data saved and stop')\n",
    "        ll = -(np.pi*mydet(Rx)).log() - (x[...,None,:].conj()@Rx.inverse()@x[...,None]).squeeze()\n",
    "    return -ll.sum().real, beta*kl\n",
    "\n",
    "#%%\n",
    "fig_loc = '../data/nem_ss/figures/'\n",
    "mod_loc = '../data/nem_ss/models/'\n",
    "if not(os.path.isdir(fig_loc + f'/{rid}/')): \n",
    "    print('made a new folder')\n",
    "    os.mkdir(fig_loc + f'{rid}/')\n",
    "    os.mkdir(mod_loc + f'{rid}/')\n",
    "fig_loc = fig_loc + f'{rid}/'\n",
    "mod_loc = mod_loc + f'{rid}/'\n",
    "\n",
    "I = 3000 # how many samples\n",
    "M, N, F, K = 3, 100, 100, 3\n",
    "NF = N*F\n",
    "eps = 5e-4\n",
    "opts = {}\n",
    "opts['batch_size'] = 64\n",
    "opts['lr'] = 1e-3\n",
    "opts['n_epochs'] = 150\n",
    "\n",
    "d = torch.load('../data/nem_ss/tr3kM3FT100.pt')\n",
    "d = awgn_batch(d, snr=30, seed=1)\n",
    "xtr = (d/d.abs().amax(dim=(1,2,3))[:,None,None,None]) # [sample,M,N,F]\n",
    "xtr = xtr.to(torch.cfloat)\n",
    "data = Data.TensorDataset(xtr[:I])\n",
    "tr = Data.DataLoader(data, batch_size=opts['batch_size'], shuffle=True, drop_last=True)\n",
    "xval, _ , hgt0 = torch.load('../data/nem_ss/val500M3FT100_xsh.pt')\n",
    "hgt = torch.tensor(hgt0).to(torch.cfloat).cuda()\n",
    "xval_cuda = xval[:128].to(torch.cfloat).cuda()\n",
    "\n",
    "loss_iter, loss_tr, loss1, loss2, loss_eval = [], [], [], [], []\n",
    "NN = NN_gtupconv\n",
    "model = NN(M,K,N).cuda()\n",
    "# for w in model.parameters():\n",
    "#     nn.init.normal_(w, mean=0., std=0.01)\n",
    "\n",
    "optimizer = RAdam(model.parameters(),\n",
    "                lr= opts['lr'],\n",
    "                betas=(0.9, 0.999), \n",
    "                eps=1e-8,\n",
    "                weight_decay=0)\n",
    "\n",
    "for epoch in range(opts['n_epochs']):\n",
    "    model.train()\n",
    "    for i, (x,) in enumerate(tr): \n",
    "        x = x.cuda()\n",
    "        optimizer.zero_grad()         \n",
    "        Rs, Hhat, Rb, mu, logvar= model(x)\n",
    "        l1, l2 = loss_fun(x, Rs, Hhat, Rb, mu, logvar)\n",
    "        loss = l1 + l2\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "        optimizer.step()\n",
    "        torch.cuda.empty_cache()\n",
    " \n",
    "    loss_tr.append(loss.detach().cpu().item()/opts['batch_size'])\n",
    "    loss1.append(l1.detach().cpu().item()/opts['batch_size'])\n",
    "    loss2.append(l2.detach().cpu().item()/opts['batch_size'])\n",
    "    if epoch%10 == 0:\n",
    "        print(epoch)\n",
    "        plt.figure()\n",
    "        plt.plot(loss_tr, '-or')\n",
    "        plt.title(f'Loss fuction at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_LossFunAll')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss1, '-og')\n",
    "        plt.title(f'Reconstruction loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_Loss1')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss2, '-og')\n",
    "        plt.title(f'KL loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_Loss2')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss_tr[-50:], '-or')\n",
    "        plt.title(f'Last 50 of loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_last50')\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            Rs, Hhat, Rb, mu, logvar= model(xval_cuda)\n",
    "            l1, l2 = loss_fun(xval_cuda, Rs, Hhat, Rb, mu, logvar)\n",
    "            loss_eval.append((l1+l2).cpu().item()/128)\n",
    "            plt.figure()\n",
    "            plt.plot(loss_eval, '-xb')\n",
    "            plt.title(f'Accumulated validation loss at epoch{epoch}')\n",
    "            plt.savefig(fig_loc + f'Epoch{epoch}_val') \n",
    "            plt.close('all')           \n",
    "        torch.save(model, mod_loc+f'model_epoch{epoch}.pt')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% s6\n",
    "rid = 's6' # running id\n",
    "from utils import *\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "torch.set_printoptions(linewidth=160)\n",
    "from datetime import datetime\n",
    "print('starting date time ', datetime.now())\n",
    "torch.manual_seed(1)\n",
    "\n",
    "if torch.__version__[:5] != '1.8.1':\n",
    "    def mydet(x):\n",
    "        return x.det()\n",
    "    RAdam = torch.optim.RAdam\n",
    "else:\n",
    "    RAdam = optim.RAdam\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "from vae_model import *\n",
    "class NN_gtupconv(nn.Module):\n",
    "    \"\"\"This is recursive Wiener filter version, with Rb threshold of [1e-3, 1e2]\n",
    "    Input shape [I,M,N,F], e.g.[32,3,100,100]\n",
    "    J <=K\n",
    "    \"\"\"\n",
    "    def __init__(self, M=3, K=3, im_size=100):\n",
    "        super().__init__()\n",
    "        self.dz = 32\n",
    "        self.K, self.M = K, M\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            Down(in_channels=1, out_channels=64),\n",
    "            DoubleConv(in_channels=64, out_channels=32),\n",
    "            Down(in_channels=32, out_channels=16),\n",
    "            DoubleConv(in_channels=16, out_channels=1),\n",
    "            )\n",
    "        self.fc1 = nn.Linear(25*25, 2*self.dz)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(self.dz, 25*25),\n",
    "            Reshape(-1, 1, 25, 25),\n",
    "            Up_(in_channels=1, out_channels=64),\n",
    "            DoubleConv(in_channels=64, out_channels=32),\n",
    "            Up_(in_channels=32, out_channels=16),\n",
    "            DoubleConv(in_channels=16, out_channels=4),\n",
    "            OutConv(in_channels=4, out_channels=1),\n",
    "            ) \n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, _, N, F = x.shape\n",
    "        z_all, v_all, h_all = [], [], []\n",
    "        I = x.shape[0]\n",
    "        \"Neural nets for H,V\"\n",
    "        shat_all = []\n",
    "        for i in range(self.K):\n",
    "            if i == 0:\n",
    "                inp = x\n",
    "            else:\n",
    "                tmp = hj[...,None]@W@inp.permute(2,3,0,1)[...,None]\n",
    "                inp = inp - tmp.squeeze().permute(2,3,0,1)\n",
    "\n",
    "            # sb = self.b2(self.b1(inp.abs()).squeeze()).mean(dim=1).exp()\n",
    "            # Rb = (sb[:None]*torch.ones(batch_size, self.M, \\\n",
    "            #     device=x.device)).diag_embed().to(torch.cfloat) # shape:[I, M, M]\n",
    "            Rb = (1.4e-3*torch.ones(batch_size, self.M, \\\n",
    "                device=x.device)).diag_embed().to(torch.cfloat) # shape:[I, M, M]\n",
    "            hj = hgt[:,i].repeat(I).reshape(I,3) # shape:[I, M]\n",
    "            h_all.append(hj)\n",
    "\n",
    "            \"Wienter filter to get coarse shat\"\n",
    "            Rx = hj[...,None] @ hj[:,None].conj() + Rb # shape of [I,M,M]\n",
    "            W = hj[:, None,].conj() @ Rx.inverse()  # shape of [N,F,I,1,M]\n",
    "            shat = (W @ inp.permute(2,3,0,1)[...,None]).squeeze().permute(2,0,1) #[I, N, F]\n",
    "            shat = shat/shat.detach().abs().max()\n",
    "            shat_all.append(shat)\n",
    "        \n",
    "        for i in range(self.K):\n",
    "            \"Encoder\"\n",
    "            xx = self.encoder(shat[:,None].abs())\n",
    "            \"Get latent variable\"\n",
    "            zz = self.fc1(xx.reshape(batch_size,-1))\n",
    "            mu = zz[:,::2]\n",
    "            logvar = zz[:,1::2]\n",
    "            z = self.reparameterize(mu, logvar)\n",
    "            z_all.append(z)\n",
    "            \n",
    "            \"Decoder to get V\"\n",
    "            v = self.decoder(z).exp()\n",
    "            v_all.append(threshold(v, floor=1e-3, ceiling=1e2)) # 1e-3 to 1e2\n",
    "        Hhat = torch.stack(h_all, 2) # shape:[I, M, K]\n",
    "        vhat = torch.stack(v_all, 4).squeeze().to(torch.cfloat) # shape:[I, N, F, K]\n",
    "\n",
    "        return vhat.diag_embed(), Hhat, Rb, mu, logvar\n",
    "\n",
    "def loss_fun(x, Rs, Hhat, Rb, mu, logvar, beta=0.1):\n",
    "    x = x.permute(0,2,3,1)\n",
    "    kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    Rxperm = Hhat @ Rs.permute(1,2,0,3,4) @ Hhat.transpose(-1,-2).conj() + Rb\n",
    "    Rx = Rxperm.permute(2,0,1,3,4) # shape of [I, N, F, M, M]\n",
    "    try:\n",
    "        ll = -(np.pi*mydet(Rx)).log() - (x[...,None,:].conj()@Rx.inverse()@x[...,None]).squeeze() \n",
    "    except:\n",
    "        torch.save((x, Rx, Rs, Hhat, Rb), f'rid{rid}x_Rx_Rs_Hhat_Rb.pt')\n",
    "        print('error happpened, data saved and stop')\n",
    "        ll = -(np.pi*mydet(Rx)).log() - (x[...,None,:].conj()@Rx.inverse()@x[...,None]).squeeze()\n",
    "    return -ll.sum().real, beta*kl\n",
    "\n",
    "#%%\n",
    "fig_loc = '../data/nem_ss/figures/'\n",
    "mod_loc = '../data/nem_ss/models/'\n",
    "if not(os.path.isdir(fig_loc + f'/{rid}/')): \n",
    "    print('made a new folder')\n",
    "    os.mkdir(fig_loc + f'{rid}/')\n",
    "    os.mkdir(mod_loc + f'{rid}/')\n",
    "fig_loc = fig_loc + f'{rid}/'\n",
    "mod_loc = mod_loc + f'{rid}/'\n",
    "\n",
    "I = 3000 # how many samples\n",
    "M, N, F, K = 3, 100, 100, 3\n",
    "NF = N*F\n",
    "eps = 5e-4\n",
    "opts = {}\n",
    "opts['batch_size'] = 64\n",
    "opts['lr'] = 1e-3\n",
    "opts['n_epochs'] = 150\n",
    "\n",
    "d = torch.load('../data/nem_ss/tr3kM3FT100.pt')\n",
    "d = awgn_batch(d, snr=30, seed=1)\n",
    "xtr = (d/d.abs().amax(dim=(1,2,3))[:,None,None,None]) # [sample,M,N,F]\n",
    "xtr = xtr.to(torch.cfloat)\n",
    "data = Data.TensorDataset(xtr[:I])\n",
    "tr = Data.DataLoader(data, batch_size=opts['batch_size'], shuffle=True, drop_last=True)\n",
    "xval, _ , hgt0 = torch.load('../data/nem_ss/val500M3FT100_xsh.pt')\n",
    "hgt = torch.tensor(hgt0).to(torch.cfloat).cuda()\n",
    "xval_cuda = xval[:128].to(torch.cfloat).cuda()\n",
    "\n",
    "loss_iter, loss_tr, loss1, loss2, loss_eval = [], [], [], [], []\n",
    "NN = NN_gtupconv\n",
    "model = NN(M,K,N).cuda()\n",
    "# for w in model.parameters():\n",
    "#     nn.init.normal_(w, mean=0., std=0.01)\n",
    "\n",
    "optimizer = RAdam(model.parameters(),\n",
    "                lr= opts['lr'],\n",
    "                betas=(0.9, 0.999), \n",
    "                eps=1e-8,\n",
    "                weight_decay=0)\n",
    "\n",
    "for epoch in range(opts['n_epochs']):\n",
    "    model.train()\n",
    "    for i, (x,) in enumerate(tr): \n",
    "        x = x.cuda()\n",
    "        optimizer.zero_grad()         \n",
    "        Rs, Hhat, Rb, mu, logvar= model(x)\n",
    "        l1, l2 = loss_fun(x, Rs, Hhat, Rb, mu, logvar)\n",
    "        loss = l1 + l2\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "        optimizer.step()\n",
    "        torch.cuda.empty_cache()\n",
    " \n",
    "    loss_tr.append(loss.detach().cpu().item()/opts['batch_size'])\n",
    "    loss1.append(l1.detach().cpu().item()/opts['batch_size'])\n",
    "    loss2.append(l2.detach().cpu().item()/opts['batch_size'])\n",
    "    if epoch%10 == 0:\n",
    "        print(epoch)\n",
    "        plt.figure()\n",
    "        plt.plot(loss_tr, '-or')\n",
    "        plt.title(f'Loss fuction at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_LossFunAll')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss1, '-og')\n",
    "        plt.title(f'Reconstruction loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_Loss1')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss2, '-og')\n",
    "        plt.title(f'KL loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_Loss2')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss_tr[-50:], '-or')\n",
    "        plt.title(f'Last 50 of loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_last50')\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            Rs, Hhat, Rb, mu, logvar= model(xval_cuda)\n",
    "            l1, l2 = loss_fun(xval_cuda, Rs, Hhat, Rb, mu, logvar)\n",
    "            loss_eval.append((l1+l2).cpu().item()/128)\n",
    "            plt.figure()\n",
    "            plt.plot(loss_eval, '-xb')\n",
    "            plt.title(f'Accumulated validation loss at epoch{epoch}')\n",
    "            plt.savefig(fig_loc + f'Epoch{epoch}_val') \n",
    "            plt.close('all')           \n",
    "        torch.save(model, mod_loc+f'model_epoch{epoch}.pt')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% s7\n",
    "rid = 's7' # running id\n",
    "from utils import *\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "torch.set_printoptions(linewidth=160)\n",
    "from datetime import datetime\n",
    "print('starting date time ', datetime.now())\n",
    "torch.manual_seed(1)\n",
    "\n",
    "if torch.__version__[:5] != '1.8.1':\n",
    "    def mydet(x):\n",
    "        return x.det()\n",
    "    RAdam = torch.optim.RAdam\n",
    "else:\n",
    "    RAdam = optim.RAdam\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "from vae_model import *\n",
    "class NN_gtupconv(nn.Module):\n",
    "    \"\"\"This is recursive Wiener filter version, with Rb threshold of [1e-3, 1e2]\n",
    "    Input shape [I,M,N,F], e.g.[32,3,100,100]\n",
    "    J <=K\n",
    "    \"\"\"\n",
    "    def __init__(self, M=3, K=3, im_size=100):\n",
    "        super().__init__()\n",
    "        self.dz = 32\n",
    "        self.K, self.M = K, M\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            Down(in_channels=1, out_channels=64),\n",
    "            DoubleConv(in_channels=64, out_channels=32),\n",
    "            Down(in_channels=32, out_channels=16),\n",
    "            DoubleConv(in_channels=16, out_channels=1),\n",
    "            )\n",
    "        self.fc1 = nn.Linear(25*25, 2*self.dz)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(self.dz, 25*25),\n",
    "            Reshape(-1, 1, 25, 25),\n",
    "            Up_(in_channels=1, out_channels=64),\n",
    "            DoubleConv(in_channels=64, out_channels=32),\n",
    "            Up_(in_channels=32, out_channels=16),\n",
    "            DoubleConv(in_channels=16, out_channels=4),\n",
    "            OutConv(in_channels=4, out_channels=1),\n",
    "            ) \n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, _, N, F = x.shape\n",
    "        z_all, v_all, h_all = [], [], []\n",
    "        I = x.shape[0]\n",
    "        \"Neural nets for H,V\"\n",
    "        shat_all = []\n",
    "        for i in range(self.K):\n",
    "            if i == 0:\n",
    "                inp = x\n",
    "            else:\n",
    "                tmp = hj[...,None]@W@inp.permute(2,3,0,1)[...,None]\n",
    "                inp = inp - tmp.squeeze().permute(2,3,0,1)\n",
    "\n",
    "            # sb = self.b2(self.b1(inp.abs()).squeeze()).mean(dim=1).exp()\n",
    "            # Rb = (sb[:None]*torch.ones(batch_size, self.M, \\\n",
    "            #     device=x.device)).diag_embed().to(torch.cfloat) # shape:[I, M, M]\n",
    "            Rb = (1.4e-3*torch.ones(batch_size, self.M, \\\n",
    "                device=x.device)).diag_embed().to(torch.cfloat) # shape:[I, M, M]\n",
    "            hj = hgt[:,i].repeat(I).reshape(I,3) # shape:[I, M]\n",
    "            h_all.append(hj)\n",
    "\n",
    "            \"Wienter filter to get coarse shat\"\n",
    "            Rx = hj[...,None] @ hj[:,None].conj() + Rb # shape of [I,M,M]\n",
    "            W = hj[:, None,].conj() @ Rx.inverse()  # shape of [N,F,I,1,M]\n",
    "            shat = (W @ inp.permute(2,3,0,1)[...,None]).squeeze().permute(2,0,1) #[I, N, F]\n",
    "            shat = shat/shat.detach().abs().max()\n",
    "            shat_all.append(shat)\n",
    "        \n",
    "        for i in range(self.K):\n",
    "            \"Encoder\"\n",
    "            xx = self.encoder(shat[:,None].abs())\n",
    "            \"Get latent variable\"\n",
    "            zz = self.fc1(xx.reshape(batch_size,-1))\n",
    "            mu = zz[:,::2]\n",
    "            logvar = zz[:,1::2]\n",
    "            z = self.reparameterize(mu, logvar)\n",
    "            z_all.append(z)\n",
    "            \n",
    "            \"Decoder to get V\"\n",
    "            v = self.decoder(z).exp()\n",
    "            v_all.append(threshold(v, floor=1e-3, ceiling=1e2)) # 1e-3 to 1e2\n",
    "        Hhat = torch.stack(h_all, 2) # shape:[I, M, K]\n",
    "        vhat = torch.stack(v_all, 4).squeeze().to(torch.cfloat) # shape:[I, N, F, K]\n",
    "\n",
    "        return vhat.diag_embed(), Hhat, Rb, mu, logvar\n",
    "\n",
    "def loss_fun(x, Rs, Hhat, Rb, mu, logvar, beta=1):\n",
    "    x = x.permute(0,2,3,1)\n",
    "    kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    Rxperm = Hhat @ Rs.permute(1,2,0,3,4) @ Hhat.transpose(-1,-2).conj() + Rb\n",
    "    Rx = Rxperm.permute(2,0,1,3,4) # shape of [I, N, F, M, M]\n",
    "    try:\n",
    "        ll = -(np.pi*mydet(Rx)).log() - (x[...,None,:].conj()@Rx.inverse()@x[...,None]).squeeze() \n",
    "    except:\n",
    "        torch.save((x, Rx, Rs, Hhat, Rb), f'rid{rid}x_Rx_Rs_Hhat_Rb.pt')\n",
    "        print('error happpened, data saved and stop')\n",
    "        ll = -(np.pi*mydet(Rx)).log() - (x[...,None,:].conj()@Rx.inverse()@x[...,None]).squeeze()\n",
    "    return -ll.sum().real, beta*kl\n",
    "\n",
    "#%%\n",
    "fig_loc = '../data/nem_ss/figures/'\n",
    "mod_loc = '../data/nem_ss/models/'\n",
    "if not(os.path.isdir(fig_loc + f'/{rid}/')): \n",
    "    print('made a new folder')\n",
    "    os.mkdir(fig_loc + f'{rid}/')\n",
    "    os.mkdir(mod_loc + f'{rid}/')\n",
    "fig_loc = fig_loc + f'{rid}/'\n",
    "mod_loc = mod_loc + f'{rid}/'\n",
    "\n",
    "I = 3000 # how many samples\n",
    "M, N, F, K = 3, 100, 100, 3\n",
    "NF = N*F\n",
    "eps = 5e-4\n",
    "opts = {}\n",
    "opts['batch_size'] = 64\n",
    "opts['lr'] = 1e-3\n",
    "opts['n_epochs'] = 150\n",
    "\n",
    "d = torch.load('../data/nem_ss/tr3kM3FT100.pt')\n",
    "d = awgn_batch(d, snr=30, seed=1)\n",
    "xtr = (d/d.abs().amax(dim=(1,2,3))[:,None,None,None]) # [sample,M,N,F]\n",
    "xtr = xtr.to(torch.cfloat)\n",
    "data = Data.TensorDataset(xtr[:I])\n",
    "tr = Data.DataLoader(data, batch_size=opts['batch_size'], shuffle=True, drop_last=True)\n",
    "xval, _ , hgt0 = torch.load('../data/nem_ss/val500M3FT100_xsh.pt')\n",
    "hgt = torch.tensor(hgt0).to(torch.cfloat).cuda()\n",
    "xval_cuda = xval[:128].to(torch.cfloat).cuda()\n",
    "\n",
    "loss_iter, loss_tr, loss1, loss2, loss_eval = [], [], [], [], []\n",
    "NN = NN_gtupconv\n",
    "model = NN(M,K,N).cuda()\n",
    "# for w in model.parameters():\n",
    "#     nn.init.normal_(w, mean=0., std=0.01)\n",
    "\n",
    "optimizer = RAdam(model.parameters(),\n",
    "                lr= opts['lr'],\n",
    "                betas=(0.9, 0.999), \n",
    "                eps=1e-8,\n",
    "                weight_decay=0)\n",
    "\n",
    "for epoch in range(opts['n_epochs']):\n",
    "    model.train()\n",
    "    for i, (x,) in enumerate(tr): \n",
    "        x = x.cuda()\n",
    "        optimizer.zero_grad()         \n",
    "        Rs, Hhat, Rb, mu, logvar= model(x)\n",
    "        l1, l2 = loss_fun(x, Rs, Hhat, Rb, mu, logvar)\n",
    "        loss = l1 + l2\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "        optimizer.step()\n",
    "        torch.cuda.empty_cache()\n",
    " \n",
    "    loss_tr.append(loss.detach().cpu().item()/opts['batch_size'])\n",
    "    loss1.append(l1.detach().cpu().item()/opts['batch_size'])\n",
    "    loss2.append(l2.detach().cpu().item()/opts['batch_size'])\n",
    "    if epoch%10 == 0:\n",
    "        print(epoch)\n",
    "        plt.figure()\n",
    "        plt.plot(loss_tr, '-or')\n",
    "        plt.title(f'Loss fuction at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_LossFunAll')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss1, '-og')\n",
    "        plt.title(f'Reconstruction loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_Loss1')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss2, '-og')\n",
    "        plt.title(f'KL loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_Loss2')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss_tr[-50:], '-or')\n",
    "        plt.title(f'Last 50 of loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_last50')\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            Rs, Hhat, Rb, mu, logvar= model(xval_cuda)\n",
    "            l1, l2 = loss_fun(xval_cuda, Rs, Hhat, Rb, mu, logvar)\n",
    "            loss_eval.append((l1+l2).cpu().item()/128)\n",
    "            plt.figure()\n",
    "            plt.plot(loss_eval, '-xb')\n",
    "            plt.title(f'Accumulated validation loss at epoch{epoch}')\n",
    "            plt.savefig(fig_loc + f'Epoch{epoch}_val') \n",
    "            plt.close('all')           \n",
    "        torch.save(model, mod_loc+f'model_epoch{epoch}.pt')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% s8\n",
    "rid = 's8' # running id\n",
    "from math import ceil\n",
    "from utils import *\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "torch.set_printoptions(linewidth=160)\n",
    "from datetime import datetime\n",
    "print('starting date time ', datetime.now())\n",
    "torch.manual_seed(1)\n",
    "\n",
    "if torch.__version__[:5] != '1.8.1':\n",
    "    def mydet(x):\n",
    "        return x.det()\n",
    "    RAdam = torch.optim.RAdam\n",
    "else:\n",
    "    RAdam = optim.RAdam\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "from vae_model import *\n",
    "class NN_gtsbd(nn.Module):\n",
    "    \"\"\"This is recursive Wiener filter version, with Rb threshold of [1e-3, 1e2]\n",
    "    Input shape [I,M,N,F], e.g.[32,3,100,100]\n",
    "    J <=K\n",
    "    \"\"\"\n",
    "    def __init__(self, M=3, K=3, im_size=100):\n",
    "        super().__init__()\n",
    "        self.dz = 32\n",
    "        self.K, self.M = K, M\n",
    "\n",
    "        # Estimate H and coarse V\n",
    "        # self.est = nn.Sequential(\n",
    "        #     Down(in_channels=M*2, out_channels=64),\n",
    "        #     Down(in_channels=64, out_channels=32),\n",
    "        #     Down(in_channels=32, out_channels=4),\n",
    "        #     Reshape(-1, 4*12*12),\n",
    "        #     LinearBlock(4*12*12, 64),\n",
    "        #     nn.Linear(64, 1),\n",
    "        #     )\n",
    "        # self.b1 = nn.Linear(100, 1)\n",
    "        # self.b2 = nn.Linear(100, 1)\n",
    "           \n",
    "        # Estimate V using auto encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            Down(in_channels=1, out_channels=64),\n",
    "            DoubleConv(in_channels=64, out_channels=32),\n",
    "            Down(in_channels=32, out_channels=16),\n",
    "            DoubleConv(in_channels=16, out_channels=1),\n",
    "            )\n",
    "        self.fc1 = nn.Linear(25*25, 2*self.dz)\n",
    "        self.decoder = nn.Sequential(\n",
    "            DoubleConv(in_channels=self.dz+2, out_channels=64),\n",
    "            DoubleConv(in_channels=64, out_channels=32),\n",
    "            DoubleConv(in_channels=32, out_channels=16),\n",
    "            DoubleConv(in_channels=16, out_channels=4),\n",
    "            OutConv(in_channels=4, out_channels=1),\n",
    "            ) \n",
    "        self.im_size = im_size\n",
    "        x = torch.linspace(-1, 1, im_size)\n",
    "        y = torch.linspace(-1, 1, im_size)\n",
    "        x_grid, y_grid = torch.meshgrid(x, y)\n",
    "        # Add as constant, with extra dims for N and C\n",
    "        self.register_buffer('x_grid', x_grid.view((1, 1) + x_grid.shape))\n",
    "        self.register_buffer('y_grid', y_grid.view((1, 1) + y_grid.shape))\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, _, N, F = x.shape\n",
    "        z_all, v_all, h_all = [], [], []\n",
    "        I = x.shape[0]\n",
    "        \"Neural nets for H,V\"\n",
    "        shat_all = []\n",
    "        for i in range(self.K):\n",
    "            if i == 0:\n",
    "                inp = x\n",
    "            else:\n",
    "                tmp = hj[...,None]@W@inp.permute(2,3,0,1)[...,None]\n",
    "                inp = inp - tmp.squeeze().permute(2,3,0,1)\n",
    "\n",
    "            # sb = self.b2(self.b1(inp.abs()).squeeze()).mean(dim=1).exp()\n",
    "            # Rb = (sb[:None]*torch.ones(batch_size, self.M, \\\n",
    "            #     device=x.device)).diag_embed().to(torch.cfloat) # shape:[I, M, M]\n",
    "            Rb = (1.4e-3*torch.ones(batch_size, self.M, \\\n",
    "                device=x.device)).diag_embed().to(torch.cfloat) # shape:[I, M, M]\n",
    "            hj = hgt[:,i].repeat(I).reshape(I,3) # shape:[I, M]\n",
    "            h_all.append(hj)\n",
    "\n",
    "            \"Wienter filter to get coarse shat\"\n",
    "            Rx = hj[...,None] @ hj[:,None].conj() + Rb # shape of [I,M,M]\n",
    "            W = hj[:, None,].conj() @ Rx.inverse()  # shape of [N,F,I,1,M]\n",
    "            shat = (W @ inp.permute(2,3,0,1)[...,None]).squeeze().permute(2,0,1) #[I, N, F]\n",
    "            shat = shat/shat.detach().abs().max()\n",
    "            shat_all.append(shat)\n",
    "        \n",
    "        for i in range(self.K):\n",
    "            \"Encoder\"\n",
    "            xx = self.encoder(shat_all[i][:,None].abs())\n",
    "            \"Get latent variable\"\n",
    "            zz = self.fc1(xx.reshape(batch_size,-1))\n",
    "            mu = zz[:,::2]\n",
    "            logvar = zz[:,1::2]\n",
    "            z = self.reparameterize(mu, logvar)\n",
    "            z_all.append(z)\n",
    "            \n",
    "            \"Decoder to get V\"\n",
    "            # View z as 4D tensor to be tiled across new N and F dimensions            \n",
    "            zr = z.view((batch_size, self.dz)+ (1, 1))  #Shape: IxDxNxF\n",
    "            # Tile across to match image size\n",
    "            zr = zr.expand(-1, -1, self.im_size, self.im_size)  #Shape: IxDx64x64\n",
    "            # Expand grids to batches and concatenate on the channel dimension\n",
    "            zbd = torch.cat((self.x_grid.expand(batch_size, -1, -1, -1),\n",
    "                        self.y_grid.expand(batch_size, -1, -1, -1), zr), dim=1) # Shape: Ix(dz*K+2)xNxF\n",
    "            v = self.decoder(zbd).exp()\n",
    "            v_all.append(threshold(v, floor=1e-3, ceiling=1e2)) # 1e-3 to 1e2\n",
    "        Hhat = torch.stack(h_all, 2) # shape:[I, M, K]\n",
    "        vhat = torch.stack(v_all, 4).squeeze().to(torch.cfloat) # shape:[I, N, F, K]\n",
    "\n",
    "        return vhat.diag_embed(), Hhat, Rb, mu, logvar\n",
    "\n",
    "def loss_fun(x, Rs, Hhat, Rb, mu, logvar, beta=1e-3):\n",
    "    x = x.permute(0,2,3,1)\n",
    "    kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    Rxperm = Hhat @ Rs.permute(1,2,0,3,4) @ Hhat.transpose(-1,-2).conj() + Rb\n",
    "    Rx = Rxperm.permute(2,0,1,3,4) # shape of [I, N, F, M, M]\n",
    "    try:\n",
    "        ll = -(np.pi*mydet(Rx)).log() - (x[...,None,:].conj()@Rx.inverse()@x[...,None]).squeeze() \n",
    "    except:\n",
    "        torch.save((x, Rx, Rs, Hhat, Rb), f'rid{rid}x_Rx_Rs_Hhat_Rb.pt')\n",
    "        print('error happpened, data saved and stop')\n",
    "        ll = -(np.pi*mydet(Rx)).log() - (x[...,None,:].conj()@Rx.inverse()@x[...,None]).squeeze()\n",
    "    return -ll.sum().real, beta*kl\n",
    "\n",
    "#%%\n",
    "fig_loc = '../data/nem_ss/figures/'\n",
    "mod_loc = '../data/nem_ss/models/'\n",
    "if not(os.path.isdir(fig_loc + f'/{rid}/')): \n",
    "    print('made a new folder')\n",
    "    os.mkdir(fig_loc + f'{rid}/')\n",
    "    os.mkdir(mod_loc + f'{rid}/')\n",
    "fig_loc = fig_loc + f'{rid}/'\n",
    "mod_loc = mod_loc + f'{rid}/'\n",
    "\n",
    "I = 3000 # how many samples\n",
    "M, N, F, K = 3, 100, 100, 3\n",
    "NF = N*F\n",
    "eps = 5e-4\n",
    "opts = {}\n",
    "opts['batch_size'] = 64\n",
    "opts['lr'] = 1e-3\n",
    "opts['n_epochs'] = 150\n",
    "\n",
    "d = torch.load('../data/nem_ss/tr3kM3FT100.pt')\n",
    "d = awgn_batch(d, snr=30, seed=1)\n",
    "xtr = (d/d.abs().amax(dim=(1,2,3))[:,None,None,None]) # [sample,M,N,F]\n",
    "xtr = xtr.to(torch.cfloat)\n",
    "data = Data.TensorDataset(xtr[:I])\n",
    "tr = Data.DataLoader(data, batch_size=opts['batch_size'], shuffle=True, drop_last=True)\n",
    "xval, _ , hgt0 = torch.load('../data/nem_ss/val500M3FT100_xsh.pt')\n",
    "hgt = torch.tensor(hgt0).to(torch.cfloat).cuda()\n",
    "xval_cuda = xval[:128].to(torch.cfloat).cuda()\n",
    "\n",
    "loss_iter, loss_tr, loss1, loss2, loss_eval = [], [], [], [], []\n",
    "NN = NN_gtsbd\n",
    "model = NN(M,K,N).cuda()\n",
    "# for w in model.parameters():\n",
    "#     nn.init.normal_(w, mean=0., std=0.01)\n",
    "\n",
    "optimizer = RAdam(model.parameters(),\n",
    "                lr= opts['lr'],\n",
    "                betas=(0.9, 0.999), \n",
    "                eps=1e-8,\n",
    "                weight_decay=0)\n",
    "\n",
    "for epoch in range(opts['n_epochs']):\n",
    "    model.train()\n",
    "    for i, (x,) in enumerate(tr): \n",
    "        x = x.cuda()\n",
    "        optimizer.zero_grad()         \n",
    "        Rs, Hhat, Rb, mu, logvar= model(x)\n",
    "        l1, l2 = loss_fun(x, Rs, Hhat, Rb, mu, logvar)\n",
    "        loss = l1 + l2\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "        optimizer.step()\n",
    "        torch.cuda.empty_cache()\n",
    " \n",
    "    loss_tr.append(loss.detach().cpu().item()/opts['batch_size'])\n",
    "    loss1.append(l1.detach().cpu().item()/opts['batch_size'])\n",
    "    loss2.append(l2.detach().cpu().item()/opts['batch_size'])\n",
    "    if epoch%10 == 0:\n",
    "        print(epoch)\n",
    "        plt.figure()\n",
    "        plt.plot(loss_tr, '-or')\n",
    "        plt.title(f'Loss fuction at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_LossFunAll')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss1, '-og')\n",
    "        plt.title(f'Reconstruction loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_Loss1')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss2, '-og')\n",
    "        plt.title(f'KL loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_Loss2')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss_tr[-50:], '-or')\n",
    "        plt.title(f'Last 50 of loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_last50')\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            Rs, Hhat, Rb, mu, logvar= model(xval_cuda)\n",
    "            l1, l2 = loss_fun(xval_cuda, Rs, Hhat, Rb, mu, logvar)\n",
    "            loss_eval.append((l1+l2).cpu().item()/128)\n",
    "            plt.figure()\n",
    "            plt.plot(loss_eval, '-xb')\n",
    "            plt.title(f'Accumulated validation loss at epoch{epoch}')\n",
    "            plt.savefig(fig_loc + f'Epoch{epoch}_val') \n",
    "            plt.close('all')           \n",
    "        torch.save(model, mod_loc+f'model_epoch{epoch}.pt')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% s9\n",
    "rid = 's9' # running id\n",
    "from math import ceil\n",
    "from utils import *\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "torch.set_printoptions(linewidth=160)\n",
    "from datetime import datetime\n",
    "print('starting date time ', datetime.now())\n",
    "torch.manual_seed(1)\n",
    "\n",
    "if torch.__version__[:5] != '1.8.1':\n",
    "    def mydet(x):\n",
    "        return x.det()\n",
    "    RAdam = torch.optim.RAdam\n",
    "else:\n",
    "    RAdam = optim.RAdam\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "from vae_model import *\n",
    "class NN_gtsbd(nn.Module):\n",
    "    \"\"\"This is recursive Wiener filter version, with Rb threshold of [1e-3, 1e2]\n",
    "    Input shape [I,M,N,F], e.g.[32,3,100,100]\n",
    "    J <=K\n",
    "    \"\"\"\n",
    "    def __init__(self, M=3, K=3, im_size=100):\n",
    "        super().__init__()\n",
    "        self.dz = 32\n",
    "        self.K, self.M = K, M\n",
    "\n",
    "        # Estimate H and coarse V\n",
    "        # self.est = nn.Sequential(\n",
    "        #     Down(in_channels=M*2, out_channels=64),\n",
    "        #     Down(in_channels=64, out_channels=32),\n",
    "        #     Down(in_channels=32, out_channels=4),\n",
    "        #     Reshape(-1, 4*12*12),\n",
    "        #     LinearBlock(4*12*12, 64),\n",
    "        #     nn.Linear(64, 1),\n",
    "        #     )\n",
    "        # self.b1 = nn.Linear(100, 1)\n",
    "        # self.b2 = nn.Linear(100, 1)\n",
    "           \n",
    "        # Estimate V using auto encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            Down(in_channels=1, out_channels=64),\n",
    "            DoubleConv(in_channels=64, out_channels=32),\n",
    "            Down(in_channels=32, out_channels=16),\n",
    "            DoubleConv(in_channels=16, out_channels=1),\n",
    "            )\n",
    "        self.fc1 = nn.Linear(25*25, 2*self.dz)\n",
    "        self.decoder = nn.Sequential(\n",
    "            DoubleConv(in_channels=self.dz+2, out_channels=64),\n",
    "            DoubleConv(in_channels=64, out_channels=32),\n",
    "            DoubleConv(in_channels=32, out_channels=16),\n",
    "            DoubleConv(in_channels=16, out_channels=4),\n",
    "            OutConv(in_channels=4, out_channels=1),\n",
    "            ) \n",
    "        self.im_size = im_size\n",
    "        x = torch.linspace(-1, 1, im_size)\n",
    "        y = torch.linspace(-1, 1, im_size)\n",
    "        x_grid, y_grid = torch.meshgrid(x, y)\n",
    "        # Add as constant, with extra dims for N and C\n",
    "        self.register_buffer('x_grid', x_grid.view((1, 1) + x_grid.shape))\n",
    "        self.register_buffer('y_grid', y_grid.view((1, 1) + y_grid.shape))\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, _, N, F = x.shape\n",
    "        z_all, v_all, h_all = [], [], []\n",
    "        I = x.shape[0]\n",
    "        \"Neural nets for H,V\"\n",
    "        shat_all = []\n",
    "        for i in range(self.K):\n",
    "            if i == 0:\n",
    "                inp = x\n",
    "            else:\n",
    "                tmp = hj[...,None]@W@inp.permute(2,3,0,1)[...,None]\n",
    "                inp = inp - tmp.squeeze().permute(2,3,0,1)\n",
    "\n",
    "            # sb = self.b2(self.b1(inp.abs()).squeeze()).mean(dim=1).exp()\n",
    "            # Rb = (sb[:None]*torch.ones(batch_size, self.M, \\\n",
    "            #     device=x.device)).diag_embed().to(torch.cfloat) # shape:[I, M, M]\n",
    "            Rb = (1.4e-3*torch.ones(batch_size, self.M, \\\n",
    "                device=x.device)).diag_embed().to(torch.cfloat) # shape:[I, M, M]\n",
    "            hj = hgt[:,i].repeat(I).reshape(I,3) # shape:[I, M]\n",
    "            h_all.append(hj)\n",
    "\n",
    "            \"Wienter filter to get coarse shat\"\n",
    "            Rx = hj[...,None] @ hj[:,None].conj() + Rb # shape of [I,M,M]\n",
    "            W = hj[:, None,].conj() @ Rx.inverse()  # shape of [N,F,I,1,M]\n",
    "            shat = (W @ inp.permute(2,3,0,1)[...,None]).squeeze().permute(2,0,1) #[I, N, F]\n",
    "            shat = shat/shat.detach().abs().max()\n",
    "            shat_all.append(shat)\n",
    "        \n",
    "        for i in range(self.K):\n",
    "            \"Encoder\"\n",
    "            xx = self.encoder(shat_all[i][:,None].abs())\n",
    "            \"Get latent variable\"\n",
    "            zz = self.fc1(xx.reshape(batch_size,-1))\n",
    "            mu = zz[:,::2]\n",
    "            logvar = zz[:,1::2]\n",
    "            z = self.reparameterize(mu, logvar)\n",
    "            z_all.append(z)\n",
    "            \n",
    "            \"Decoder to get V\"\n",
    "            # View z as 4D tensor to be tiled across new N and F dimensions            \n",
    "            zr = z.view((batch_size, self.dz)+ (1, 1))  #Shape: IxDxNxF\n",
    "            # Tile across to match image size\n",
    "            zr = zr.expand(-1, -1, self.im_size, self.im_size)  #Shape: IxDx64x64\n",
    "            # Expand grids to batches and concatenate on the channel dimension\n",
    "            zbd = torch.cat((self.x_grid.expand(batch_size, -1, -1, -1),\n",
    "                        self.y_grid.expand(batch_size, -1, -1, -1), zr), dim=1) # Shape: Ix(dz*K+2)xNxF\n",
    "            v = self.decoder(zbd).exp()\n",
    "            v_all.append(threshold(v, floor=1e-3, ceiling=1e2)) # 1e-3 to 1e2\n",
    "        Hhat = torch.stack(h_all, 2) # shape:[I, M, K]\n",
    "        vhat = torch.stack(v_all, 4).squeeze().to(torch.cfloat) # shape:[I, N, F, K]\n",
    "\n",
    "        return vhat.diag_embed(), Hhat, Rb, mu, logvar\n",
    "\n",
    "def loss_fun(x, Rs, Hhat, Rb, mu, logvar, beta=1e-2):\n",
    "    x = x.permute(0,2,3,1)\n",
    "    kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    Rxperm = Hhat @ Rs.permute(1,2,0,3,4) @ Hhat.transpose(-1,-2).conj() + Rb\n",
    "    Rx = Rxperm.permute(2,0,1,3,4) # shape of [I, N, F, M, M]\n",
    "    try:\n",
    "        ll = -(np.pi*mydet(Rx)).log() - (x[...,None,:].conj()@Rx.inverse()@x[...,None]).squeeze() \n",
    "    except:\n",
    "        torch.save((x, Rx, Rs, Hhat, Rb), f'rid{rid}x_Rx_Rs_Hhat_Rb.pt')\n",
    "        print('error happpened, data saved and stop')\n",
    "        ll = -(np.pi*mydet(Rx)).log() - (x[...,None,:].conj()@Rx.inverse()@x[...,None]).squeeze()\n",
    "    return -ll.sum().real, beta*kl\n",
    "\n",
    "#%%\n",
    "fig_loc = '../data/nem_ss/figures/'\n",
    "mod_loc = '../data/nem_ss/models/'\n",
    "if not(os.path.isdir(fig_loc + f'/{rid}/')): \n",
    "    print('made a new folder')\n",
    "    os.mkdir(fig_loc + f'{rid}/')\n",
    "    os.mkdir(mod_loc + f'{rid}/')\n",
    "fig_loc = fig_loc + f'{rid}/'\n",
    "mod_loc = mod_loc + f'{rid}/'\n",
    "\n",
    "I = 3000 # how many samples\n",
    "M, N, F, K = 3, 100, 100, 3\n",
    "NF = N*F\n",
    "eps = 5e-4\n",
    "opts = {}\n",
    "opts['batch_size'] = 64\n",
    "opts['lr'] = 1e-3\n",
    "opts['n_epochs'] = 150\n",
    "\n",
    "d = torch.load('../data/nem_ss/tr3kM3FT100.pt')\n",
    "d = awgn_batch(d, snr=30, seed=1)\n",
    "xtr = (d/d.abs().amax(dim=(1,2,3))[:,None,None,None]) # [sample,M,N,F]\n",
    "xtr = xtr.to(torch.cfloat)\n",
    "data = Data.TensorDataset(xtr[:I])\n",
    "tr = Data.DataLoader(data, batch_size=opts['batch_size'], shuffle=True, drop_last=True)\n",
    "xval, _ , hgt0 = torch.load('../data/nem_ss/val500M3FT100_xsh.pt')\n",
    "hgt = torch.tensor(hgt0).to(torch.cfloat).cuda()\n",
    "xval_cuda = xval[:128].to(torch.cfloat).cuda()\n",
    "\n",
    "loss_iter, loss_tr, loss1, loss2, loss_eval = [], [], [], [], []\n",
    "NN = NN_gtsbd\n",
    "model = NN(M,K,N).cuda()\n",
    "# for w in model.parameters():\n",
    "#     nn.init.normal_(w, mean=0., std=0.01)\n",
    "\n",
    "optimizer = RAdam(model.parameters(),\n",
    "                lr= opts['lr'],\n",
    "                betas=(0.9, 0.999), \n",
    "                eps=1e-8,\n",
    "                weight_decay=0)\n",
    "\n",
    "for epoch in range(opts['n_epochs']):\n",
    "    model.train()\n",
    "    for i, (x,) in enumerate(tr): \n",
    "        x = x.cuda()\n",
    "        optimizer.zero_grad()         \n",
    "        Rs, Hhat, Rb, mu, logvar= model(x)\n",
    "        l1, l2 = loss_fun(x, Rs, Hhat, Rb, mu, logvar)\n",
    "        loss = l1 + l2\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "        optimizer.step()\n",
    "        torch.cuda.empty_cache()\n",
    " \n",
    "    loss_tr.append(loss.detach().cpu().item()/opts['batch_size'])\n",
    "    loss1.append(l1.detach().cpu().item()/opts['batch_size'])\n",
    "    loss2.append(l2.detach().cpu().item()/opts['batch_size'])\n",
    "    if epoch%10 == 0:\n",
    "        print(epoch)\n",
    "        plt.figure()\n",
    "        plt.plot(loss_tr, '-or')\n",
    "        plt.title(f'Loss fuction at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_LossFunAll')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss1, '-og')\n",
    "        plt.title(f'Reconstruction loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_Loss1')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss2, '-og')\n",
    "        plt.title(f'KL loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_Loss2')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss_tr[-50:], '-or')\n",
    "        plt.title(f'Last 50 of loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_last50')\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            Rs, Hhat, Rb, mu, logvar= model(xval_cuda)\n",
    "            l1, l2 = loss_fun(xval_cuda, Rs, Hhat, Rb, mu, logvar)\n",
    "            loss_eval.append((l1+l2).cpu().item()/128)\n",
    "            plt.figure()\n",
    "            plt.plot(loss_eval, '-xb')\n",
    "            plt.title(f'Accumulated validation loss at epoch{epoch}')\n",
    "            plt.savefig(fig_loc + f'Epoch{epoch}_val') \n",
    "            plt.close('all')           \n",
    "        torch.save(model, mod_loc+f'model_epoch{epoch}.pt')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% s10\n",
    "rid = 's10' # running id\n",
    "from math import ceil\n",
    "from utils import *\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "torch.set_printoptions(linewidth=160)\n",
    "from datetime import datetime\n",
    "print('starting date time ', datetime.now())\n",
    "torch.manual_seed(1)\n",
    "\n",
    "if torch.__version__[:5] != '1.8.1':\n",
    "    def mydet(x):\n",
    "        return x.det()\n",
    "    RAdam = torch.optim.RAdam\n",
    "else:\n",
    "    RAdam = optim.RAdam\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "from vae_model import *\n",
    "class NN_gtsbd(nn.Module):\n",
    "    \"\"\"This is recursive Wiener filter version, with Rb threshold of [1e-3, 1e2]\n",
    "    Input shape [I,M,N,F], e.g.[32,3,100,100]\n",
    "    J <=K\n",
    "    \"\"\"\n",
    "    def __init__(self, M=3, K=3, im_size=100):\n",
    "        super().__init__()\n",
    "        self.dz = 32\n",
    "        self.K, self.M = K, M\n",
    "\n",
    "        # Estimate H and coarse V\n",
    "        # self.est = nn.Sequential(\n",
    "        #     Down(in_channels=M*2, out_channels=64),\n",
    "        #     Down(in_channels=64, out_channels=32),\n",
    "        #     Down(in_channels=32, out_channels=4),\n",
    "        #     Reshape(-1, 4*12*12),\n",
    "        #     LinearBlock(4*12*12, 64),\n",
    "        #     nn.Linear(64, 1),\n",
    "        #     )\n",
    "        # self.b1 = nn.Linear(100, 1)\n",
    "        # self.b2 = nn.Linear(100, 1)\n",
    "           \n",
    "        # Estimate V using auto encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            Down(in_channels=1, out_channels=64),\n",
    "            DoubleConv(in_channels=64, out_channels=32),\n",
    "            Down(in_channels=32, out_channels=16),\n",
    "            DoubleConv(in_channels=16, out_channels=1),\n",
    "            )\n",
    "        self.fc1 = nn.Linear(25*25, 2*self.dz)\n",
    "        self.decoder = nn.Sequential(\n",
    "            DoubleConv(in_channels=self.dz+2, out_channels=64),\n",
    "            DoubleConv(in_channels=64, out_channels=32),\n",
    "            DoubleConv(in_channels=32, out_channels=16),\n",
    "            DoubleConv(in_channels=16, out_channels=4),\n",
    "            OutConv(in_channels=4, out_channels=1),\n",
    "            ) \n",
    "        self.im_size = im_size\n",
    "        x = torch.linspace(-1, 1, im_size)\n",
    "        y = torch.linspace(-1, 1, im_size)\n",
    "        x_grid, y_grid = torch.meshgrid(x, y)\n",
    "        # Add as constant, with extra dims for N and C\n",
    "        self.register_buffer('x_grid', x_grid.view((1, 1) + x_grid.shape))\n",
    "        self.register_buffer('y_grid', y_grid.view((1, 1) + y_grid.shape))\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, _, N, F = x.shape\n",
    "        z_all, v_all, h_all = [], [], []\n",
    "        I = x.shape[0]\n",
    "        \"Neural nets for H,V\"\n",
    "        shat_all = []\n",
    "        for i in range(self.K):\n",
    "            if i == 0:\n",
    "                inp = x\n",
    "            else:\n",
    "                tmp = hj[...,None]@W@inp.permute(2,3,0,1)[...,None]\n",
    "                inp = inp - tmp.squeeze().permute(2,3,0,1)\n",
    "\n",
    "            # sb = self.b2(self.b1(inp.abs()).squeeze()).mean(dim=1).exp()\n",
    "            # Rb = (sb[:None]*torch.ones(batch_size, self.M, \\\n",
    "            #     device=x.device)).diag_embed().to(torch.cfloat) # shape:[I, M, M]\n",
    "            Rb = (1.4e-3*torch.ones(batch_size, self.M, \\\n",
    "                device=x.device)).diag_embed().to(torch.cfloat) # shape:[I, M, M]\n",
    "            hj = hgt[:,i].repeat(I).reshape(I,3) # shape:[I, M]\n",
    "            h_all.append(hj)\n",
    "\n",
    "            \"Wienter filter to get coarse shat\"\n",
    "            Rx = hj[...,None] @ hj[:,None].conj() + Rb # shape of [I,M,M]\n",
    "            W = hj[:, None,].conj() @ Rx.inverse()  # shape of [N,F,I,1,M]\n",
    "            shat = (W @ inp.permute(2,3,0,1)[...,None]).squeeze().permute(2,0,1) #[I, N, F]\n",
    "            shat = shat/shat.detach().abs().max()\n",
    "            shat_all.append(shat)\n",
    "        \n",
    "        for i in range(self.K):\n",
    "            \"Encoder\"\n",
    "            xx = self.encoder(shat_all[i][:,None].abs())\n",
    "            \"Get latent variable\"\n",
    "            zz = self.fc1(xx.reshape(batch_size,-1))\n",
    "            mu = zz[:,::2]\n",
    "            logvar = zz[:,1::2]\n",
    "            z = self.reparameterize(mu, logvar)\n",
    "            z_all.append(z)\n",
    "            \n",
    "            \"Decoder to get V\"\n",
    "            # View z as 4D tensor to be tiled across new N and F dimensions            \n",
    "            zr = z.view((batch_size, self.dz)+ (1, 1))  #Shape: IxDxNxF\n",
    "            # Tile across to match image size\n",
    "            zr = zr.expand(-1, -1, self.im_size, self.im_size)  #Shape: IxDx64x64\n",
    "            # Expand grids to batches and concatenate on the channel dimension\n",
    "            zbd = torch.cat((self.x_grid.expand(batch_size, -1, -1, -1),\n",
    "                        self.y_grid.expand(batch_size, -1, -1, -1), zr), dim=1) # Shape: Ix(dz*K+2)xNxF\n",
    "            v = self.decoder(zbd).exp()\n",
    "            v_all.append(threshold(v, floor=1e-3, ceiling=1e2)) # 1e-3 to 1e2\n",
    "        Hhat = torch.stack(h_all, 2) # shape:[I, M, K]\n",
    "        vhat = torch.stack(v_all, 4).squeeze().to(torch.cfloat) # shape:[I, N, F, K]\n",
    "\n",
    "        return vhat.diag_embed(), Hhat, Rb, mu, logvar\n",
    "\n",
    "def loss_fun(x, Rs, Hhat, Rb, mu, logvar, beta=0.1):\n",
    "    x = x.permute(0,2,3,1)\n",
    "    kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    Rxperm = Hhat @ Rs.permute(1,2,0,3,4) @ Hhat.transpose(-1,-2).conj() + Rb\n",
    "    Rx = Rxperm.permute(2,0,1,3,4) # shape of [I, N, F, M, M]\n",
    "    try:\n",
    "        ll = -(np.pi*mydet(Rx)).log() - (x[...,None,:].conj()@Rx.inverse()@x[...,None]).squeeze() \n",
    "    except:\n",
    "        torch.save((x, Rx, Rs, Hhat, Rb), f'rid{rid}x_Rx_Rs_Hhat_Rb.pt')\n",
    "        print('error happpened, data saved and stop')\n",
    "        ll = -(np.pi*mydet(Rx)).log() - (x[...,None,:].conj()@Rx.inverse()@x[...,None]).squeeze()\n",
    "    return -ll.sum().real, beta*kl\n",
    "\n",
    "#%%\n",
    "fig_loc = '../data/nem_ss/figures/'\n",
    "mod_loc = '../data/nem_ss/models/'\n",
    "if not(os.path.isdir(fig_loc + f'/{rid}/')): \n",
    "    print('made a new folder')\n",
    "    os.mkdir(fig_loc + f'{rid}/')\n",
    "    os.mkdir(mod_loc + f'{rid}/')\n",
    "fig_loc = fig_loc + f'{rid}/'\n",
    "mod_loc = mod_loc + f'{rid}/'\n",
    "\n",
    "I = 3000 # how many samples\n",
    "M, N, F, K = 3, 100, 100, 3\n",
    "NF = N*F\n",
    "eps = 5e-4\n",
    "opts = {}\n",
    "opts['batch_size'] = 64\n",
    "opts['lr'] = 1e-3\n",
    "opts['n_epochs'] = 150\n",
    "\n",
    "d = torch.load('../data/nem_ss/tr3kM3FT100.pt')\n",
    "d = awgn_batch(d, snr=30, seed=1)\n",
    "xtr = (d/d.abs().amax(dim=(1,2,3))[:,None,None,None]) # [sample,M,N,F]\n",
    "xtr = xtr.to(torch.cfloat)\n",
    "data = Data.TensorDataset(xtr[:I])\n",
    "tr = Data.DataLoader(data, batch_size=opts['batch_size'], shuffle=True, drop_last=True)\n",
    "xval, _ , hgt0 = torch.load('../data/nem_ss/val500M3FT100_xsh.pt')\n",
    "hgt = torch.tensor(hgt0).to(torch.cfloat).cuda()\n",
    "xval_cuda = xval[:128].to(torch.cfloat).cuda()\n",
    "\n",
    "loss_iter, loss_tr, loss1, loss2, loss_eval = [], [], [], [], []\n",
    "NN = NN_gtsbd\n",
    "model = NN(M,K,N).cuda()\n",
    "# for w in model.parameters():\n",
    "#     nn.init.normal_(w, mean=0., std=0.01)\n",
    "\n",
    "optimizer = RAdam(model.parameters(),\n",
    "                lr= opts['lr'],\n",
    "                betas=(0.9, 0.999), \n",
    "                eps=1e-8,\n",
    "                weight_decay=0)\n",
    "\n",
    "for epoch in range(opts['n_epochs']):\n",
    "    model.train()\n",
    "    for i, (x,) in enumerate(tr): \n",
    "        x = x.cuda()\n",
    "        optimizer.zero_grad()         \n",
    "        Rs, Hhat, Rb, mu, logvar= model(x)\n",
    "        l1, l2 = loss_fun(x, Rs, Hhat, Rb, mu, logvar)\n",
    "        loss = l1 + l2\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "        optimizer.step()\n",
    "        torch.cuda.empty_cache()\n",
    " \n",
    "    loss_tr.append(loss.detach().cpu().item()/opts['batch_size'])\n",
    "    loss1.append(l1.detach().cpu().item()/opts['batch_size'])\n",
    "    loss2.append(l2.detach().cpu().item()/opts['batch_size'])\n",
    "    if epoch%10 == 0:\n",
    "        print(epoch)\n",
    "        plt.figure()\n",
    "        plt.plot(loss_tr, '-or')\n",
    "        plt.title(f'Loss fuction at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_LossFunAll')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss1, '-og')\n",
    "        plt.title(f'Reconstruction loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_Loss1')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss2, '-og')\n",
    "        plt.title(f'KL loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_Loss2')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss_tr[-50:], '-or')\n",
    "        plt.title(f'Last 50 of loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_last50')\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            Rs, Hhat, Rb, mu, logvar= model(xval_cuda)\n",
    "            l1, l2 = loss_fun(xval_cuda, Rs, Hhat, Rb, mu, logvar)\n",
    "            loss_eval.append((l1+l2).cpu().item()/128)\n",
    "            plt.figure()\n",
    "            plt.plot(loss_eval, '-xb')\n",
    "            plt.title(f'Accumulated validation loss at epoch{epoch}')\n",
    "            plt.savefig(fig_loc + f'Epoch{epoch}_val') \n",
    "            plt.close('all')           \n",
    "        torch.save(model, mod_loc+f'model_epoch{epoch}.pt')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% s11\n",
    "rid = 's11' # running id\n",
    "from math import ceil\n",
    "from utils import *\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "torch.set_printoptions(linewidth=160)\n",
    "from datetime import datetime\n",
    "print('starting date time ', datetime.now())\n",
    "torch.manual_seed(1)\n",
    "\n",
    "if torch.__version__[:5] != '1.8.1':\n",
    "    def mydet(x):\n",
    "        return x.det()\n",
    "    RAdam = torch.optim.RAdam\n",
    "else:\n",
    "    RAdam = optim.RAdam\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "from vae_model import *\n",
    "class NN_gtsbd(nn.Module):\n",
    "    \"\"\"This is recursive Wiener filter version, with Rb threshold of [1e-3, 1e2]\n",
    "    Input shape [I,M,N,F], e.g.[32,3,100,100]\n",
    "    J <=K\n",
    "    \"\"\"\n",
    "    def __init__(self, M=3, K=3, im_size=100):\n",
    "        super().__init__()\n",
    "        self.dz = 32\n",
    "        self.K, self.M = K, M\n",
    "\n",
    "        # Estimate H and coarse V\n",
    "        # self.est = nn.Sequential(\n",
    "        #     Down(in_channels=M*2, out_channels=64),\n",
    "        #     Down(in_channels=64, out_channels=32),\n",
    "        #     Down(in_channels=32, out_channels=4),\n",
    "        #     Reshape(-1, 4*12*12),\n",
    "        #     LinearBlock(4*12*12, 64),\n",
    "        #     nn.Linear(64, 1),\n",
    "        #     )\n",
    "        # self.b1 = nn.Linear(100, 1)\n",
    "        # self.b2 = nn.Linear(100, 1)\n",
    "           \n",
    "        # Estimate V using auto encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            Down(in_channels=1, out_channels=64),\n",
    "            DoubleConv(in_channels=64, out_channels=32),\n",
    "            Down(in_channels=32, out_channels=16),\n",
    "            DoubleConv(in_channels=16, out_channels=1),\n",
    "            )\n",
    "        self.fc1 = nn.Linear(25*25, 2*self.dz)\n",
    "        self.decoder = nn.Sequential(\n",
    "            DoubleConv(in_channels=self.dz+2, out_channels=64),\n",
    "            DoubleConv(in_channels=64, out_channels=32),\n",
    "            DoubleConv(in_channels=32, out_channels=16),\n",
    "            DoubleConv(in_channels=16, out_channels=4),\n",
    "            OutConv(in_channels=4, out_channels=1),\n",
    "            ) \n",
    "        self.im_size = im_size\n",
    "        x = torch.linspace(-1, 1, im_size)\n",
    "        y = torch.linspace(-1, 1, im_size)\n",
    "        x_grid, y_grid = torch.meshgrid(x, y)\n",
    "        # Add as constant, with extra dims for N and C\n",
    "        self.register_buffer('x_grid', x_grid.view((1, 1) + x_grid.shape))\n",
    "        self.register_buffer('y_grid', y_grid.view((1, 1) + y_grid.shape))\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, _, N, F = x.shape\n",
    "        z_all, v_all, h_all = [], [], []\n",
    "        I = x.shape[0]\n",
    "        \"Neural nets for H,V\"\n",
    "        shat_all = []\n",
    "        for i in range(self.K):\n",
    "            if i == 0:\n",
    "                inp = x\n",
    "            else:\n",
    "                tmp = hj[...,None]@W@inp.permute(2,3,0,1)[...,None]\n",
    "                inp = inp - tmp.squeeze().permute(2,3,0,1)\n",
    "\n",
    "            # sb = self.b2(self.b1(inp.abs()).squeeze()).mean(dim=1).exp()\n",
    "            # Rb = (sb[:None]*torch.ones(batch_size, self.M, \\\n",
    "            #     device=x.device)).diag_embed().to(torch.cfloat) # shape:[I, M, M]\n",
    "            Rb = (1.4e-3*torch.ones(batch_size, self.M, \\\n",
    "                device=x.device)).diag_embed().to(torch.cfloat) # shape:[I, M, M]\n",
    "            hj = hgt[:,i].repeat(I).reshape(I,3) # shape:[I, M]\n",
    "            h_all.append(hj)\n",
    "\n",
    "            \"Wienter filter to get coarse shat\"\n",
    "            Rx = hj[...,None] @ hj[:,None].conj() + Rb # shape of [I,M,M]\n",
    "            W = hj[:, None,].conj() @ Rx.inverse()  # shape of [N,F,I,1,M]\n",
    "            shat = (W @ inp.permute(2,3,0,1)[...,None]).squeeze().permute(2,0,1) #[I, N, F]\n",
    "            shat = shat/shat.detach().abs().max()\n",
    "            shat_all.append(shat)\n",
    "        \n",
    "        for i in range(self.K):\n",
    "            \"Encoder\"\n",
    "            xx = self.encoder(shat_all[i][:,None].abs())\n",
    "            \"Get latent variable\"\n",
    "            zz = self.fc1(xx.reshape(batch_size,-1))\n",
    "            mu = zz[:,::2]\n",
    "            logvar = zz[:,1::2]\n",
    "            z = self.reparameterize(mu, logvar)\n",
    "            z_all.append(z)\n",
    "            \n",
    "            \"Decoder to get V\"\n",
    "            # View z as 4D tensor to be tiled across new N and F dimensions            \n",
    "            zr = z.view((batch_size, self.dz)+ (1, 1))  #Shape: IxDxNxF\n",
    "            # Tile across to match image size\n",
    "            zr = zr.expand(-1, -1, self.im_size, self.im_size)  #Shape: IxDx64x64\n",
    "            # Expand grids to batches and concatenate on the channel dimension\n",
    "            zbd = torch.cat((self.x_grid.expand(batch_size, -1, -1, -1),\n",
    "                        self.y_grid.expand(batch_size, -1, -1, -1), zr), dim=1) # Shape: Ix(dz*K+2)xNxF\n",
    "            v = self.decoder(zbd).exp()\n",
    "            v_all.append(threshold(v, floor=1e-3, ceiling=1e2)) # 1e-3 to 1e2\n",
    "        Hhat = torch.stack(h_all, 2) # shape:[I, M, K]\n",
    "        vhat = torch.stack(v_all, 4).squeeze().to(torch.cfloat) # shape:[I, N, F, K]\n",
    "\n",
    "        return vhat.diag_embed(), Hhat, Rb, mu, logvar\n",
    "\n",
    "def loss_fun(x, Rs, Hhat, Rb, mu, logvar, beta=1):\n",
    "    x = x.permute(0,2,3,1)\n",
    "    kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    Rxperm = Hhat @ Rs.permute(1,2,0,3,4) @ Hhat.transpose(-1,-2).conj() + Rb\n",
    "    Rx = Rxperm.permute(2,0,1,3,4) # shape of [I, N, F, M, M]\n",
    "    try:\n",
    "        ll = -(np.pi*mydet(Rx)).log() - (x[...,None,:].conj()@Rx.inverse()@x[...,None]).squeeze() \n",
    "    except:\n",
    "        torch.save((x, Rx, Rs, Hhat, Rb), f'rid{rid}x_Rx_Rs_Hhat_Rb.pt')\n",
    "        print('error happpened, data saved and stop')\n",
    "        ll = -(np.pi*mydet(Rx)).log() - (x[...,None,:].conj()@Rx.inverse()@x[...,None]).squeeze()\n",
    "    return -ll.sum().real, beta*kl\n",
    "\n",
    "#%%\n",
    "fig_loc = '../data/nem_ss/figures/'\n",
    "mod_loc = '../data/nem_ss/models/'\n",
    "if not(os.path.isdir(fig_loc + f'/{rid}/')): \n",
    "    print('made a new folder')\n",
    "    os.mkdir(fig_loc + f'{rid}/')\n",
    "    os.mkdir(mod_loc + f'{rid}/')\n",
    "fig_loc = fig_loc + f'{rid}/'\n",
    "mod_loc = mod_loc + f'{rid}/'\n",
    "\n",
    "I = 3000 # how many samples\n",
    "M, N, F, K = 3, 100, 100, 3\n",
    "NF = N*F\n",
    "eps = 5e-4\n",
    "opts = {}\n",
    "opts['batch_size'] = 64\n",
    "opts['lr'] = 1e-3\n",
    "opts['n_epochs'] = 150\n",
    "\n",
    "d = torch.load('../data/nem_ss/tr3kM3FT100.pt')\n",
    "d = awgn_batch(d, snr=30, seed=1)\n",
    "xtr = (d/d.abs().amax(dim=(1,2,3))[:,None,None,None]) # [sample,M,N,F]\n",
    "xtr = xtr.to(torch.cfloat)\n",
    "data = Data.TensorDataset(xtr[:I])\n",
    "tr = Data.DataLoader(data, batch_size=opts['batch_size'], shuffle=True, drop_last=True)\n",
    "xval, _ , hgt0 = torch.load('../data/nem_ss/val500M3FT100_xsh.pt')\n",
    "hgt = torch.tensor(hgt0).to(torch.cfloat).cuda()\n",
    "xval_cuda = xval[:128].to(torch.cfloat).cuda()\n",
    "\n",
    "loss_iter, loss_tr, loss1, loss2, loss_eval = [], [], [], [], []\n",
    "NN = NN_gtsbd\n",
    "model = NN(M,K,N).cuda()\n",
    "# for w in model.parameters():\n",
    "#     nn.init.normal_(w, mean=0., std=0.01)\n",
    "\n",
    "optimizer = RAdam(model.parameters(),\n",
    "                lr= opts['lr'],\n",
    "                betas=(0.9, 0.999), \n",
    "                eps=1e-8,\n",
    "                weight_decay=0)\n",
    "\n",
    "for epoch in range(opts['n_epochs']):\n",
    "    model.train()\n",
    "    for i, (x,) in enumerate(tr): \n",
    "        x = x.cuda()\n",
    "        optimizer.zero_grad()         \n",
    "        Rs, Hhat, Rb, mu, logvar= model(x)\n",
    "        l1, l2 = loss_fun(x, Rs, Hhat, Rb, mu, logvar)\n",
    "        loss = l1 + l2\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "        optimizer.step()\n",
    "        torch.cuda.empty_cache()\n",
    " \n",
    "    loss_tr.append(loss.detach().cpu().item()/opts['batch_size'])\n",
    "    loss1.append(l1.detach().cpu().item()/opts['batch_size'])\n",
    "    loss2.append(l2.detach().cpu().item()/opts['batch_size'])\n",
    "    if epoch%10 == 0:\n",
    "        print(epoch)\n",
    "        plt.figure()\n",
    "        plt.plot(loss_tr, '-or')\n",
    "        plt.title(f'Loss fuction at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_LossFunAll')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss1, '-og')\n",
    "        plt.title(f'Reconstruction loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_Loss1')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss2, '-og')\n",
    "        plt.title(f'KL loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_Loss2')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss_tr[-50:], '-or')\n",
    "        plt.title(f'Last 50 of loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_last50')\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            Rs, Hhat, Rb, mu, logvar= model(xval_cuda)\n",
    "            l1, l2 = loss_fun(xval_cuda, Rs, Hhat, Rb, mu, logvar)\n",
    "            loss_eval.append((l1+l2).cpu().item()/128)\n",
    "            plt.figure()\n",
    "            plt.plot(loss_eval, '-xb')\n",
    "            plt.title(f'Accumulated validation loss at epoch{epoch}')\n",
    "            plt.savefig(fig_loc + f'Epoch{epoch}_val') \n",
    "            plt.close('all')           \n",
    "        torch.save(model, mod_loc+f'model_epoch{epoch}.pt')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% s12\n",
    "rid = 's12' # running id\n",
    "from utils import *\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "torch.set_printoptions(linewidth=160)\n",
    "from datetime import datetime\n",
    "print('starting date time ', datetime.now())\n",
    "torch.manual_seed(1)\n",
    "\n",
    "if torch.__version__[:5] != '1.8.1':\n",
    "    def mydet(x):\n",
    "        return x.det()\n",
    "    RAdam = torch.optim.RAdam\n",
    "else:\n",
    "    RAdam = optim.RAdam\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "from vae_model import *\n",
    "class NN_gtupconv_less(nn.Module):\n",
    "    \"\"\"This is recursive Wiener filter version, with Rb threshold of [1e-3, 1e2]\n",
    "    Input shape [I,M,N,F], e.g.[32,3,100,100]\n",
    "    J <=K\n",
    "    \"\"\"\n",
    "    def __init__(self, M=3, K=3, im_size=100):\n",
    "        super().__init__()\n",
    "        self.dz = 32\n",
    "        self.K, self.M = K, M\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            Down(in_channels=1, out_channels=64),\n",
    "            Down(in_channels=64, out_channels=16),\n",
    "            OutConv(in_channels=16, out_channels=1),\n",
    "            )\n",
    "        self.fc1 = nn.Linear(25*25, 2*self.dz)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(self.dz, 25*25),\n",
    "            Reshape(-1, 1, 25, 25),\n",
    "            Up_(in_channels=1, out_channels=64),\n",
    "            Up_(in_channels=64, out_channels=16),\n",
    "            OutConv(in_channels=16, out_channels=1),\n",
    "            ) \n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, _, N, F = x.shape\n",
    "        z_all, v_all, h_all = [], [], []\n",
    "        I = x.shape[0]\n",
    "        \"Neural nets for H,V\"\n",
    "        shat_all = []\n",
    "        for i in range(self.K):\n",
    "            if i == 0:\n",
    "                inp = x\n",
    "            else:\n",
    "                tmp = hj[...,None]@W@inp.permute(2,3,0,1)[...,None]\n",
    "                inp = inp - tmp.squeeze().permute(2,3,0,1)\n",
    "\n",
    "            # sb = self.b2(self.b1(inp.abs()).squeeze()).mean(dim=1).exp()\n",
    "            # Rb = (sb[:None]*torch.ones(batch_size, self.M, \\\n",
    "            #     device=x.device)).diag_embed().to(torch.cfloat) # shape:[I, M, M]\n",
    "            Rb = (1.4e-3*torch.ones(batch_size, self.M, \\\n",
    "                device=x.device)).diag_embed().to(torch.cfloat) # shape:[I, M, M]\n",
    "            hj = hgt[:,i].repeat(I).reshape(I,3) # shape:[I, M]\n",
    "            h_all.append(hj)\n",
    "\n",
    "            \"Wienter filter to get coarse shat\"\n",
    "            Rx = hj[...,None] @ hj[:,None].conj() + Rb # shape of [I,M,M]\n",
    "            W = hj[:, None,].conj() @ Rx.inverse()  # shape of [N,F,I,1,M]\n",
    "            shat = (W @ inp.permute(2,3,0,1)[...,None]).squeeze().permute(2,0,1) #[I, N, F]\n",
    "            shat = shat/shat.detach().abs().max()\n",
    "            shat_all.append(shat)\n",
    "        \n",
    "        for i in range(self.K):\n",
    "            \"Encoder\"\n",
    "            xx = self.encoder(shat[:,None].abs())\n",
    "            \"Get latent variable\"\n",
    "            zz = self.fc1(xx.reshape(batch_size,-1))\n",
    "            mu = zz[:,::2]\n",
    "            logvar = zz[:,1::2]\n",
    "            z = self.reparameterize(mu, logvar)\n",
    "            z_all.append(z)\n",
    "            \n",
    "            \"Decoder to get V\"\n",
    "            v = self.decoder(z).exp()\n",
    "            v_all.append(threshold(v, floor=1e-3, ceiling=1e2)) # 1e-3 to 1e2\n",
    "        Hhat = torch.stack(h_all, 2) # shape:[I, M, K]\n",
    "        vhat = torch.stack(v_all, 4).squeeze().to(torch.cfloat) # shape:[I, N, F, K]\n",
    "\n",
    "        return vhat.diag_embed(), Hhat, Rb, mu, logvar\n",
    "\n",
    "def loss_fun(x, Rs, Hhat, Rb, mu, logvar, beta=1e-3):\n",
    "    x = x.permute(0,2,3,1)\n",
    "    kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    Rxperm = Hhat @ Rs.permute(1,2,0,3,4) @ Hhat.transpose(-1,-2).conj() + Rb\n",
    "    Rx = Rxperm.permute(2,0,1,3,4) # shape of [I, N, F, M, M]\n",
    "    try:\n",
    "        ll = -(np.pi*mydet(Rx)).log() - (x[...,None,:].conj()@Rx.inverse()@x[...,None]).squeeze() \n",
    "    except:\n",
    "        torch.save((x, Rx, Rs, Hhat, Rb), f'rid{rid}x_Rx_Rs_Hhat_Rb.pt')\n",
    "        print('error happpened, data saved and stop')\n",
    "        ll = -(np.pi*mydet(Rx)).log() - (x[...,None,:].conj()@Rx.inverse()@x[...,None]).squeeze()\n",
    "    return -ll.sum().real, beta*kl\n",
    "\n",
    "#%%\n",
    "fig_loc = '../data/nem_ss/figures/'\n",
    "mod_loc = '../data/nem_ss/models/'\n",
    "if not(os.path.isdir(fig_loc + f'/{rid}/')): \n",
    "    print('made a new folder')\n",
    "    os.mkdir(fig_loc + f'{rid}/')\n",
    "    os.mkdir(mod_loc + f'{rid}/')\n",
    "fig_loc = fig_loc + f'{rid}/'\n",
    "mod_loc = mod_loc + f'{rid}/'\n",
    "\n",
    "I = 3000 # how many samples\n",
    "M, N, F, K = 3, 100, 100, 3\n",
    "NF = N*F\n",
    "eps = 5e-4\n",
    "opts = {}\n",
    "opts['batch_size'] = 64\n",
    "opts['lr'] = 1e-3\n",
    "opts['n_epochs'] = 150\n",
    "\n",
    "d = torch.load('../data/nem_ss/tr3kM3FT100.pt')\n",
    "d = awgn_batch(d, snr=30, seed=1)\n",
    "xtr = (d/d.abs().amax(dim=(1,2,3))[:,None,None,None]) # [sample,M,N,F]\n",
    "xtr = xtr.to(torch.cfloat)\n",
    "data = Data.TensorDataset(xtr[:I])\n",
    "tr = Data.DataLoader(data, batch_size=opts['batch_size'], shuffle=True, drop_last=True)\n",
    "xval, _ , hgt0 = torch.load('../data/nem_ss/val500M3FT100_xsh.pt')\n",
    "hgt = torch.tensor(hgt0).to(torch.cfloat).cuda()\n",
    "xval_cuda = xval[:128].to(torch.cfloat).cuda()\n",
    "\n",
    "loss_iter, loss_tr, loss1, loss2, loss_eval = [], [], [], [], []\n",
    "NN = NN_gtupconv_less\n",
    "model = NN(M,K,N).cuda()\n",
    "# for w in model.parameters():\n",
    "#     nn.init.normal_(w, mean=0., std=0.01)\n",
    "\n",
    "optimizer = RAdam(model.parameters(),\n",
    "                lr= opts['lr'],\n",
    "                betas=(0.9, 0.999), \n",
    "                eps=1e-8,\n",
    "                weight_decay=0)\n",
    "\n",
    "for epoch in range(opts['n_epochs']):\n",
    "    model.train()\n",
    "    for i, (x,) in enumerate(tr): \n",
    "        x = x.cuda()\n",
    "        optimizer.zero_grad()         \n",
    "        Rs, Hhat, Rb, mu, logvar= model(x)\n",
    "        l1, l2 = loss_fun(x, Rs, Hhat, Rb, mu, logvar)\n",
    "        loss = l1 + l2\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "        optimizer.step()\n",
    "        torch.cuda.empty_cache()\n",
    " \n",
    "    loss_tr.append(loss.detach().cpu().item()/opts['batch_size'])\n",
    "    loss1.append(l1.detach().cpu().item()/opts['batch_size'])\n",
    "    loss2.append(l2.detach().cpu().item()/opts['batch_size'])\n",
    "    if epoch%10 == 0:\n",
    "        print(epoch)\n",
    "        plt.figure()\n",
    "        plt.plot(loss_tr, '-or')\n",
    "        plt.title(f'Loss fuction at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_LossFunAll')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss1, '-og')\n",
    "        plt.title(f'Reconstruction loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_Loss1')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss2, '-og')\n",
    "        plt.title(f'KL loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_Loss2')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss_tr[-50:], '-or')\n",
    "        plt.title(f'Last 50 of loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_last50')\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            Rs, Hhat, Rb, mu, logvar= model(xval_cuda)\n",
    "            l1, l2 = loss_fun(xval_cuda, Rs, Hhat, Rb, mu, logvar)\n",
    "            loss_eval.append((l1+l2).cpu().item()/128)\n",
    "            plt.figure()\n",
    "            plt.plot(loss_eval, '-xb')\n",
    "            plt.title(f'Accumulated validation loss at epoch{epoch}')\n",
    "            plt.savefig(fig_loc + f'Epoch{epoch}_val') \n",
    "            plt.close('all')           \n",
    "        torch.save(model, mod_loc+f'model_epoch{epoch}.pt')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% s13\n",
    "rid = 's13' # running id\n",
    "from utils import *\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "torch.set_printoptions(linewidth=160)\n",
    "from datetime import datetime\n",
    "print('starting date time ', datetime.now())\n",
    "torch.manual_seed(1)\n",
    "\n",
    "if torch.__version__[:5] != '1.8.1':\n",
    "    def mydet(x):\n",
    "        return x.det()\n",
    "    RAdam = torch.optim.RAdam\n",
    "else:\n",
    "    RAdam = optim.RAdam\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "from vae_model import *\n",
    "class NN_gtupconv_less(nn.Module):\n",
    "    \"\"\"This is recursive Wiener filter version, with Rb threshold of [1e-3, 1e2]\n",
    "    Input shape [I,M,N,F], e.g.[32,3,100,100]\n",
    "    J <=K\n",
    "    \"\"\"\n",
    "    def __init__(self, M=3, K=3, im_size=100):\n",
    "        super().__init__()\n",
    "        self.dz = 32\n",
    "        self.K, self.M = K, M\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            Down(in_channels=1, out_channels=64),\n",
    "            Down(in_channels=64, out_channels=16),\n",
    "            OutConv(in_channels=16, out_channels=1),\n",
    "            )\n",
    "        self.fc1 = nn.Linear(25*25, 2*self.dz)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(self.dz, 25*25),\n",
    "            Reshape(-1, 1, 25, 25),\n",
    "            Up_(in_channels=1, out_channels=64),\n",
    "            Up_(in_channels=64, out_channels=16),\n",
    "            OutConv(in_channels=16, out_channels=1),\n",
    "            ) \n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, _, N, F = x.shape\n",
    "        z_all, v_all, h_all = [], [], []\n",
    "        I = x.shape[0]\n",
    "        \"Neural nets for H,V\"\n",
    "        shat_all = []\n",
    "        for i in range(self.K):\n",
    "            if i == 0:\n",
    "                inp = x\n",
    "            else:\n",
    "                tmp = hj[...,None]@W@inp.permute(2,3,0,1)[...,None]\n",
    "                inp = inp - tmp.squeeze().permute(2,3,0,1)\n",
    "\n",
    "            # sb = self.b2(self.b1(inp.abs()).squeeze()).mean(dim=1).exp()\n",
    "            # Rb = (sb[:None]*torch.ones(batch_size, self.M, \\\n",
    "            #     device=x.device)).diag_embed().to(torch.cfloat) # shape:[I, M, M]\n",
    "            Rb = (1.4e-3*torch.ones(batch_size, self.M, \\\n",
    "                device=x.device)).diag_embed().to(torch.cfloat) # shape:[I, M, M]\n",
    "            hj = hgt[:,i].repeat(I).reshape(I,3) # shape:[I, M]\n",
    "            h_all.append(hj)\n",
    "\n",
    "            \"Wienter filter to get coarse shat\"\n",
    "            Rx = hj[...,None] @ hj[:,None].conj() + Rb # shape of [I,M,M]\n",
    "            W = hj[:, None,].conj() @ Rx.inverse()  # shape of [N,F,I,1,M]\n",
    "            shat = (W @ inp.permute(2,3,0,1)[...,None]).squeeze().permute(2,0,1) #[I, N, F]\n",
    "            shat = shat/shat.detach().abs().max()\n",
    "            shat_all.append(shat)\n",
    "        \n",
    "        for i in range(self.K):\n",
    "            \"Encoder\"\n",
    "            xx = self.encoder(shat[:,None].abs())\n",
    "            \"Get latent variable\"\n",
    "            zz = self.fc1(xx.reshape(batch_size,-1))\n",
    "            mu = zz[:,::2]\n",
    "            logvar = zz[:,1::2]\n",
    "            z = self.reparameterize(mu, logvar)\n",
    "            z_all.append(z)\n",
    "            \n",
    "            \"Decoder to get V\"\n",
    "            v = self.decoder(z).exp()\n",
    "            v_all.append(threshold(v, floor=1e-3, ceiling=1e2)) # 1e-3 to 1e2\n",
    "        Hhat = torch.stack(h_all, 2) # shape:[I, M, K]\n",
    "        vhat = torch.stack(v_all, 4).squeeze().to(torch.cfloat) # shape:[I, N, F, K]\n",
    "\n",
    "        return vhat.diag_embed(), Hhat, Rb, mu, logvar\n",
    "\n",
    "def loss_fun(x, Rs, Hhat, Rb, mu, logvar, beta=1e-2):\n",
    "    x = x.permute(0,2,3,1)\n",
    "    kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    Rxperm = Hhat @ Rs.permute(1,2,0,3,4) @ Hhat.transpose(-1,-2).conj() + Rb\n",
    "    Rx = Rxperm.permute(2,0,1,3,4) # shape of [I, N, F, M, M]\n",
    "    try:\n",
    "        ll = -(np.pi*mydet(Rx)).log() - (x[...,None,:].conj()@Rx.inverse()@x[...,None]).squeeze() \n",
    "    except:\n",
    "        torch.save((x, Rx, Rs, Hhat, Rb), f'rid{rid}x_Rx_Rs_Hhat_Rb.pt')\n",
    "        print('error happpened, data saved and stop')\n",
    "        ll = -(np.pi*mydet(Rx)).log() - (x[...,None,:].conj()@Rx.inverse()@x[...,None]).squeeze()\n",
    "    return -ll.sum().real, beta*kl\n",
    "\n",
    "#%%\n",
    "fig_loc = '../data/nem_ss/figures/'\n",
    "mod_loc = '../data/nem_ss/models/'\n",
    "if not(os.path.isdir(fig_loc + f'/{rid}/')): \n",
    "    print('made a new folder')\n",
    "    os.mkdir(fig_loc + f'{rid}/')\n",
    "    os.mkdir(mod_loc + f'{rid}/')\n",
    "fig_loc = fig_loc + f'{rid}/'\n",
    "mod_loc = mod_loc + f'{rid}/'\n",
    "\n",
    "I = 3000 # how many samples\n",
    "M, N, F, K = 3, 100, 100, 3\n",
    "NF = N*F\n",
    "eps = 5e-4\n",
    "opts = {}\n",
    "opts['batch_size'] = 64\n",
    "opts['lr'] = 1e-3\n",
    "opts['n_epochs'] = 150\n",
    "\n",
    "d = torch.load('../data/nem_ss/tr3kM3FT100.pt')\n",
    "d = awgn_batch(d, snr=30, seed=1)\n",
    "xtr = (d/d.abs().amax(dim=(1,2,3))[:,None,None,None]) # [sample,M,N,F]\n",
    "xtr = xtr.to(torch.cfloat)\n",
    "data = Data.TensorDataset(xtr[:I])\n",
    "tr = Data.DataLoader(data, batch_size=opts['batch_size'], shuffle=True, drop_last=True)\n",
    "xval, _ , hgt0 = torch.load('../data/nem_ss/val500M3FT100_xsh.pt')\n",
    "hgt = torch.tensor(hgt0).to(torch.cfloat).cuda()\n",
    "xval_cuda = xval[:128].to(torch.cfloat).cuda()\n",
    "\n",
    "loss_iter, loss_tr, loss1, loss2, loss_eval = [], [], [], [], []\n",
    "NN = NN_gtupconv_less\n",
    "model = NN(M,K,N).cuda()\n",
    "# for w in model.parameters():\n",
    "#     nn.init.normal_(w, mean=0., std=0.01)\n",
    "\n",
    "optimizer = RAdam(model.parameters(),\n",
    "                lr= opts['lr'],\n",
    "                betas=(0.9, 0.999), \n",
    "                eps=1e-8,\n",
    "                weight_decay=0)\n",
    "\n",
    "for epoch in range(opts['n_epochs']):\n",
    "    model.train()\n",
    "    for i, (x,) in enumerate(tr): \n",
    "        x = x.cuda()\n",
    "        optimizer.zero_grad()         \n",
    "        Rs, Hhat, Rb, mu, logvar= model(x)\n",
    "        l1, l2 = loss_fun(x, Rs, Hhat, Rb, mu, logvar)\n",
    "        loss = l1 + l2\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "        optimizer.step()\n",
    "        torch.cuda.empty_cache()\n",
    " \n",
    "    loss_tr.append(loss.detach().cpu().item()/opts['batch_size'])\n",
    "    loss1.append(l1.detach().cpu().item()/opts['batch_size'])\n",
    "    loss2.append(l2.detach().cpu().item()/opts['batch_size'])\n",
    "    if epoch%10 == 0:\n",
    "        print(epoch)\n",
    "        plt.figure()\n",
    "        plt.plot(loss_tr, '-or')\n",
    "        plt.title(f'Loss fuction at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_LossFunAll')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss1, '-og')\n",
    "        plt.title(f'Reconstruction loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_Loss1')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss2, '-og')\n",
    "        plt.title(f'KL loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_Loss2')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss_tr[-50:], '-or')\n",
    "        plt.title(f'Last 50 of loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_last50')\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            Rs, Hhat, Rb, mu, logvar= model(xval_cuda)\n",
    "            l1, l2 = loss_fun(xval_cuda, Rs, Hhat, Rb, mu, logvar)\n",
    "            loss_eval.append((l1+l2).cpu().item()/128)\n",
    "            plt.figure()\n",
    "            plt.plot(loss_eval, '-xb')\n",
    "            plt.title(f'Accumulated validation loss at epoch{epoch}')\n",
    "            plt.savefig(fig_loc + f'Epoch{epoch}_val') \n",
    "            plt.close('all')           \n",
    "        torch.save(model, mod_loc+f'model_epoch{epoch}.pt')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% s14\n",
    "rid = 's14' # running id\n",
    "from utils import *\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "torch.set_printoptions(linewidth=160)\n",
    "from datetime import datetime\n",
    "print('starting date time ', datetime.now())\n",
    "torch.manual_seed(1)\n",
    "\n",
    "if torch.__version__[:5] != '1.8.1':\n",
    "    def mydet(x):\n",
    "        return x.det()\n",
    "    RAdam = torch.optim.RAdam\n",
    "else:\n",
    "    RAdam = optim.RAdam\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "from vae_model import *\n",
    "class NN_gtupconv_less(nn.Module):\n",
    "    \"\"\"This is recursive Wiener filter version, with Rb threshold of [1e-3, 1e2]\n",
    "    Input shape [I,M,N,F], e.g.[32,3,100,100]\n",
    "    J <=K\n",
    "    \"\"\"\n",
    "    def __init__(self, M=3, K=3, im_size=100):\n",
    "        super().__init__()\n",
    "        self.dz = 32\n",
    "        self.K, self.M = K, M\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            Down(in_channels=1, out_channels=64),\n",
    "            Down(in_channels=64, out_channels=16),\n",
    "            OutConv(in_channels=16, out_channels=1),\n",
    "            )\n",
    "        self.fc1 = nn.Linear(25*25, 2*self.dz)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(self.dz, 25*25),\n",
    "            Reshape(-1, 1, 25, 25),\n",
    "            Up_(in_channels=1, out_channels=64),\n",
    "            Up_(in_channels=64, out_channels=16),\n",
    "            OutConv(in_channels=16, out_channels=1),\n",
    "            ) \n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, _, N, F = x.shape\n",
    "        z_all, v_all, h_all = [], [], []\n",
    "        I = x.shape[0]\n",
    "        \"Neural nets for H,V\"\n",
    "        shat_all = []\n",
    "        for i in range(self.K):\n",
    "            if i == 0:\n",
    "                inp = x\n",
    "            else:\n",
    "                tmp = hj[...,None]@W@inp.permute(2,3,0,1)[...,None]\n",
    "                inp = inp - tmp.squeeze().permute(2,3,0,1)\n",
    "\n",
    "            # sb = self.b2(self.b1(inp.abs()).squeeze()).mean(dim=1).exp()\n",
    "            # Rb = (sb[:None]*torch.ones(batch_size, self.M, \\\n",
    "            #     device=x.device)).diag_embed().to(torch.cfloat) # shape:[I, M, M]\n",
    "            Rb = (1.4e-3*torch.ones(batch_size, self.M, \\\n",
    "                device=x.device)).diag_embed().to(torch.cfloat) # shape:[I, M, M]\n",
    "            hj = hgt[:,i].repeat(I).reshape(I,3) # shape:[I, M]\n",
    "            h_all.append(hj)\n",
    "\n",
    "            \"Wienter filter to get coarse shat\"\n",
    "            Rx = hj[...,None] @ hj[:,None].conj() + Rb # shape of [I,M,M]\n",
    "            W = hj[:, None,].conj() @ Rx.inverse()  # shape of [N,F,I,1,M]\n",
    "            shat = (W @ inp.permute(2,3,0,1)[...,None]).squeeze().permute(2,0,1) #[I, N, F]\n",
    "            shat = shat/shat.detach().abs().max()\n",
    "            shat_all.append(shat)\n",
    "        \n",
    "        for i in range(self.K):\n",
    "            \"Encoder\"\n",
    "            xx = self.encoder(shat[:,None].abs())\n",
    "            \"Get latent variable\"\n",
    "            zz = self.fc1(xx.reshape(batch_size,-1))\n",
    "            mu = zz[:,::2]\n",
    "            logvar = zz[:,1::2]\n",
    "            z = self.reparameterize(mu, logvar)\n",
    "            z_all.append(z)\n",
    "            \n",
    "            \"Decoder to get V\"\n",
    "            v = self.decoder(z).exp()\n",
    "            v_all.append(threshold(v, floor=1e-3, ceiling=1e2)) # 1e-3 to 1e2\n",
    "        Hhat = torch.stack(h_all, 2) # shape:[I, M, K]\n",
    "        vhat = torch.stack(v_all, 4).squeeze().to(torch.cfloat) # shape:[I, N, F, K]\n",
    "\n",
    "        return vhat.diag_embed(), Hhat, Rb, mu, logvar\n",
    "\n",
    "def loss_fun(x, Rs, Hhat, Rb, mu, logvar, beta=0.1):\n",
    "    x = x.permute(0,2,3,1)\n",
    "    kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    Rxperm = Hhat @ Rs.permute(1,2,0,3,4) @ Hhat.transpose(-1,-2).conj() + Rb\n",
    "    Rx = Rxperm.permute(2,0,1,3,4) # shape of [I, N, F, M, M]\n",
    "    try:\n",
    "        ll = -(np.pi*mydet(Rx)).log() - (x[...,None,:].conj()@Rx.inverse()@x[...,None]).squeeze() \n",
    "    except:\n",
    "        torch.save((x, Rx, Rs, Hhat, Rb), f'rid{rid}x_Rx_Rs_Hhat_Rb.pt')\n",
    "        print('error happpened, data saved and stop')\n",
    "        ll = -(np.pi*mydet(Rx)).log() - (x[...,None,:].conj()@Rx.inverse()@x[...,None]).squeeze()\n",
    "    return -ll.sum().real, beta*kl\n",
    "\n",
    "#%%\n",
    "fig_loc = '../data/nem_ss/figures/'\n",
    "mod_loc = '../data/nem_ss/models/'\n",
    "if not(os.path.isdir(fig_loc + f'/{rid}/')): \n",
    "    print('made a new folder')\n",
    "    os.mkdir(fig_loc + f'{rid}/')\n",
    "    os.mkdir(mod_loc + f'{rid}/')\n",
    "fig_loc = fig_loc + f'{rid}/'\n",
    "mod_loc = mod_loc + f'{rid}/'\n",
    "\n",
    "I = 3000 # how many samples\n",
    "M, N, F, K = 3, 100, 100, 3\n",
    "NF = N*F\n",
    "eps = 5e-4\n",
    "opts = {}\n",
    "opts['batch_size'] = 64\n",
    "opts['lr'] = 1e-3\n",
    "opts['n_epochs'] = 150\n",
    "\n",
    "d = torch.load('../data/nem_ss/tr3kM3FT100.pt')\n",
    "d = awgn_batch(d, snr=30, seed=1)\n",
    "xtr = (d/d.abs().amax(dim=(1,2,3))[:,None,None,None]) # [sample,M,N,F]\n",
    "xtr = xtr.to(torch.cfloat)\n",
    "data = Data.TensorDataset(xtr[:I])\n",
    "tr = Data.DataLoader(data, batch_size=opts['batch_size'], shuffle=True, drop_last=True)\n",
    "xval, _ , hgt0 = torch.load('../data/nem_ss/val500M3FT100_xsh.pt')\n",
    "hgt = torch.tensor(hgt0).to(torch.cfloat).cuda()\n",
    "xval_cuda = xval[:128].to(torch.cfloat).cuda()\n",
    "\n",
    "loss_iter, loss_tr, loss1, loss2, loss_eval = [], [], [], [], []\n",
    "NN = NN_gtupconv_less\n",
    "model = NN(M,K,N).cuda()\n",
    "# for w in model.parameters():\n",
    "#     nn.init.normal_(w, mean=0., std=0.01)\n",
    "\n",
    "optimizer = RAdam(model.parameters(),\n",
    "                lr= opts['lr'],\n",
    "                betas=(0.9, 0.999), \n",
    "                eps=1e-8,\n",
    "                weight_decay=0)\n",
    "\n",
    "for epoch in range(opts['n_epochs']):\n",
    "    model.train()\n",
    "    for i, (x,) in enumerate(tr): \n",
    "        x = x.cuda()\n",
    "        optimizer.zero_grad()         \n",
    "        Rs, Hhat, Rb, mu, logvar= model(x)\n",
    "        l1, l2 = loss_fun(x, Rs, Hhat, Rb, mu, logvar)\n",
    "        loss = l1 + l2\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "        optimizer.step()\n",
    "        torch.cuda.empty_cache()\n",
    " \n",
    "    loss_tr.append(loss.detach().cpu().item()/opts['batch_size'])\n",
    "    loss1.append(l1.detach().cpu().item()/opts['batch_size'])\n",
    "    loss2.append(l2.detach().cpu().item()/opts['batch_size'])\n",
    "    if epoch%10 == 0:\n",
    "        print(epoch)\n",
    "        plt.figure()\n",
    "        plt.plot(loss_tr, '-or')\n",
    "        plt.title(f'Loss fuction at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_LossFunAll')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss1, '-og')\n",
    "        plt.title(f'Reconstruction loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_Loss1')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss2, '-og')\n",
    "        plt.title(f'KL loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_Loss2')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss_tr[-50:], '-or')\n",
    "        plt.title(f'Last 50 of loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_last50')\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            Rs, Hhat, Rb, mu, logvar= model(xval_cuda)\n",
    "            l1, l2 = loss_fun(xval_cuda, Rs, Hhat, Rb, mu, logvar)\n",
    "            loss_eval.append((l1+l2).cpu().item()/128)\n",
    "            plt.figure()\n",
    "            plt.plot(loss_eval, '-xb')\n",
    "            plt.title(f'Accumulated validation loss at epoch{epoch}')\n",
    "            plt.savefig(fig_loc + f'Epoch{epoch}_val') \n",
    "            plt.close('all')           \n",
    "        torch.save(model, mod_loc+f'model_epoch{epoch}.pt')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% s15\n",
    "rid = 's15' # running id\n",
    "from utils import *\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "torch.set_printoptions(linewidth=160)\n",
    "from datetime import datetime\n",
    "print('starting date time ', datetime.now())\n",
    "torch.manual_seed(1)\n",
    "\n",
    "if torch.__version__[:5] != '1.8.1':\n",
    "    def mydet(x):\n",
    "        return x.det()\n",
    "    RAdam = torch.optim.RAdam\n",
    "else:\n",
    "    RAdam = optim.RAdam\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "from vae_model import *\n",
    "class NN_gtupconv_less(nn.Module):\n",
    "    \"\"\"This is recursive Wiener filter version, with Rb threshold of [1e-3, 1e2]\n",
    "    Input shape [I,M,N,F], e.g.[32,3,100,100]\n",
    "    J <=K\n",
    "    \"\"\"\n",
    "    def __init__(self, M=3, K=3, im_size=100):\n",
    "        super().__init__()\n",
    "        self.dz = 32\n",
    "        self.K, self.M = K, M\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            Down(in_channels=1, out_channels=64),\n",
    "            Down(in_channels=64, out_channels=16),\n",
    "            OutConv(in_channels=16, out_channels=1),\n",
    "            )\n",
    "        self.fc1 = nn.Linear(25*25, 2*self.dz)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(self.dz, 25*25),\n",
    "            Reshape(-1, 1, 25, 25),\n",
    "            Up_(in_channels=1, out_channels=64),\n",
    "            Up_(in_channels=64, out_channels=16),\n",
    "            OutConv(in_channels=16, out_channels=1),\n",
    "            ) \n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, _, N, F = x.shape\n",
    "        z_all, v_all, h_all = [], [], []\n",
    "        I = x.shape[0]\n",
    "        \"Neural nets for H,V\"\n",
    "        shat_all = []\n",
    "        for i in range(self.K):\n",
    "            if i == 0:\n",
    "                inp = x\n",
    "            else:\n",
    "                tmp = hj[...,None]@W@inp.permute(2,3,0,1)[...,None]\n",
    "                inp = inp - tmp.squeeze().permute(2,3,0,1)\n",
    "\n",
    "            # sb = self.b2(self.b1(inp.abs()).squeeze()).mean(dim=1).exp()\n",
    "            # Rb = (sb[:None]*torch.ones(batch_size, self.M, \\\n",
    "            #     device=x.device)).diag_embed().to(torch.cfloat) # shape:[I, M, M]\n",
    "            Rb = (1.4e-3*torch.ones(batch_size, self.M, \\\n",
    "                device=x.device)).diag_embed().to(torch.cfloat) # shape:[I, M, M]\n",
    "            hj = hgt[:,i].repeat(I).reshape(I,3) # shape:[I, M]\n",
    "            h_all.append(hj)\n",
    "\n",
    "            \"Wienter filter to get coarse shat\"\n",
    "            Rx = hj[...,None] @ hj[:,None].conj() + Rb # shape of [I,M,M]\n",
    "            W = hj[:, None,].conj() @ Rx.inverse()  # shape of [N,F,I,1,M]\n",
    "            shat = (W @ inp.permute(2,3,0,1)[...,None]).squeeze().permute(2,0,1) #[I, N, F]\n",
    "            shat = shat/shat.detach().abs().max()\n",
    "            shat_all.append(shat)\n",
    "        \n",
    "        for i in range(self.K):\n",
    "            \"Encoder\"\n",
    "            xx = self.encoder(shat[:,None].abs())\n",
    "            \"Get latent variable\"\n",
    "            zz = self.fc1(xx.reshape(batch_size,-1))\n",
    "            mu = zz[:,::2]\n",
    "            logvar = zz[:,1::2]\n",
    "            z = self.reparameterize(mu, logvar)\n",
    "            z_all.append(z)\n",
    "            \n",
    "            \"Decoder to get V\"\n",
    "            v = self.decoder(z).exp()\n",
    "            v_all.append(threshold(v, floor=1e-3, ceiling=1e2)) # 1e-3 to 1e2\n",
    "        Hhat = torch.stack(h_all, 2) # shape:[I, M, K]\n",
    "        vhat = torch.stack(v_all, 4).squeeze().to(torch.cfloat) # shape:[I, N, F, K]\n",
    "\n",
    "        return vhat.diag_embed(), Hhat, Rb, mu, logvar\n",
    "\n",
    "def loss_fun(x, Rs, Hhat, Rb, mu, logvar, beta=1):\n",
    "    x = x.permute(0,2,3,1)\n",
    "    kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    Rxperm = Hhat @ Rs.permute(1,2,0,3,4) @ Hhat.transpose(-1,-2).conj() + Rb\n",
    "    Rx = Rxperm.permute(2,0,1,3,4) # shape of [I, N, F, M, M]\n",
    "    try:\n",
    "        ll = -(np.pi*mydet(Rx)).log() - (x[...,None,:].conj()@Rx.inverse()@x[...,None]).squeeze() \n",
    "    except:\n",
    "        torch.save((x, Rx, Rs, Hhat, Rb), f'rid{rid}x_Rx_Rs_Hhat_Rb.pt')\n",
    "        print('error happpened, data saved and stop')\n",
    "        ll = -(np.pi*mydet(Rx)).log() - (x[...,None,:].conj()@Rx.inverse()@x[...,None]).squeeze()\n",
    "    return -ll.sum().real, beta*kl\n",
    "\n",
    "#%%\n",
    "fig_loc = '../data/nem_ss/figures/'\n",
    "mod_loc = '../data/nem_ss/models/'\n",
    "if not(os.path.isdir(fig_loc + f'/{rid}/')): \n",
    "    print('made a new folder')\n",
    "    os.mkdir(fig_loc + f'{rid}/')\n",
    "    os.mkdir(mod_loc + f'{rid}/')\n",
    "fig_loc = fig_loc + f'{rid}/'\n",
    "mod_loc = mod_loc + f'{rid}/'\n",
    "\n",
    "I = 3000 # how many samples\n",
    "M, N, F, K = 3, 100, 100, 3\n",
    "NF = N*F\n",
    "eps = 5e-4\n",
    "opts = {}\n",
    "opts['batch_size'] = 64\n",
    "opts['lr'] = 1e-3\n",
    "opts['n_epochs'] = 150\n",
    "\n",
    "d = torch.load('../data/nem_ss/tr3kM3FT100.pt')\n",
    "d = awgn_batch(d, snr=30, seed=1)\n",
    "xtr = (d/d.abs().amax(dim=(1,2,3))[:,None,None,None]) # [sample,M,N,F]\n",
    "xtr = xtr.to(torch.cfloat)\n",
    "data = Data.TensorDataset(xtr[:I])\n",
    "tr = Data.DataLoader(data, batch_size=opts['batch_size'], shuffle=True, drop_last=True)\n",
    "xval, _ , hgt0 = torch.load('../data/nem_ss/val500M3FT100_xsh.pt')\n",
    "hgt = torch.tensor(hgt0).to(torch.cfloat).cuda()\n",
    "xval_cuda = xval[:128].to(torch.cfloat).cuda()\n",
    "\n",
    "loss_iter, loss_tr, loss1, loss2, loss_eval = [], [], [], [], []\n",
    "NN = NN_gtupconv_less\n",
    "model = NN(M,K,N).cuda()\n",
    "# for w in model.parameters():\n",
    "#     nn.init.normal_(w, mean=0., std=0.01)\n",
    "\n",
    "optimizer = RAdam(model.parameters(),\n",
    "                lr= opts['lr'],\n",
    "                betas=(0.9, 0.999), \n",
    "                eps=1e-8,\n",
    "                weight_decay=0)\n",
    "\n",
    "for epoch in range(opts['n_epochs']):\n",
    "    model.train()\n",
    "    for i, (x,) in enumerate(tr): \n",
    "        x = x.cuda()\n",
    "        optimizer.zero_grad()         \n",
    "        Rs, Hhat, Rb, mu, logvar= model(x)\n",
    "        l1, l2 = loss_fun(x, Rs, Hhat, Rb, mu, logvar)\n",
    "        loss = l1 + l2\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "        optimizer.step()\n",
    "        torch.cuda.empty_cache()\n",
    " \n",
    "    loss_tr.append(loss.detach().cpu().item()/opts['batch_size'])\n",
    "    loss1.append(l1.detach().cpu().item()/opts['batch_size'])\n",
    "    loss2.append(l2.detach().cpu().item()/opts['batch_size'])\n",
    "    if epoch%10 == 0:\n",
    "        print(epoch)\n",
    "        plt.figure()\n",
    "        plt.plot(loss_tr, '-or')\n",
    "        plt.title(f'Loss fuction at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_LossFunAll')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss1, '-og')\n",
    "        plt.title(f'Reconstruction loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_Loss1')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss2, '-og')\n",
    "        plt.title(f'KL loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_Loss2')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss_tr[-50:], '-or')\n",
    "        plt.title(f'Last 50 of loss at epoch{epoch}')\n",
    "        plt.savefig(fig_loc + f'Epoch{epoch}_last50')\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            Rs, Hhat, Rb, mu, logvar= model(xval_cuda)\n",
    "            l1, l2 = loss_fun(xval_cuda, Rs, Hhat, Rb, mu, logvar)\n",
    "            loss_eval.append((l1+l2).cpu().item()/128)\n",
    "            plt.figure()\n",
    "            plt.plot(loss_eval, '-xb')\n",
    "            plt.title(f'Accumulated validation loss at epoch{epoch}')\n",
    "            plt.savefig(fig_loc + f'Epoch{epoch}_val') \n",
    "            plt.close('all')           \n",
    "        torch.save(model, mod_loc+f'model_epoch{epoch}.pt')\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
